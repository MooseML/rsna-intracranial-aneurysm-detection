{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a9b077e",
   "metadata": {
    "papermill": {
     "duration": 0.006774,
     "end_time": "2025-09-25T21:36:08.508619",
     "exception": false,
     "start_time": "2025-09-25T21:36:08.501845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pipeline\n",
    "1. **DICOM → 3D Volume**: Normalize to `(32, 384, 384)`\n",
    "2. **EfficientNetV2-S**: 32-channel input, 14 binary outputs\n",
    "3. **Ensemble**: Average 5-fold predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1d4acd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T21:36:08.522228Z",
     "iopub.status.busy": "2025-09-25T21:36:08.521246Z",
     "iopub.status.idle": "2025-09-25T21:36:08.525910Z",
     "shell.execute_reply": "2025-09-25T21:36:08.525108Z"
    },
    "papermill": {
     "duration": 0.01304,
     "end_time": "2025-09-25T21:36:08.527453",
     "exception": false,
     "start_time": "2025-09-25T21:36:08.514413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import timm\n",
    "# print(\"timm version:\", timm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b47892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T21:36:08.540033Z",
     "iopub.status.busy": "2025-09-25T21:36:08.539734Z",
     "iopub.status.idle": "2025-09-25T21:36:08.544021Z",
     "shell.execute_reply": "2025-09-25T21:36:08.543216Z"
    },
    "papermill": {
     "duration": 0.012243,
     "end_time": "2025-09-25T21:36:08.545458",
     "exception": false,
     "start_time": "2025-09-25T21:36:08.533215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import timm, pprint\n",
    "\n",
    "# # all models (long list)\n",
    "# all_models = timm.list_models()\n",
    "# print(len(all_models), \"models available\")\n",
    "# for pat in [\n",
    "#     \"*convnextv2*\",\n",
    "#     \"*efficientnetv2*\",\n",
    "#     \"*maxvit*\",\n",
    "#     \"*regnet*\",\n",
    "#     \"*vit_*patch16*\",\n",
    "#     \"*swin*\",\n",
    "# ]:\n",
    "#     print(\"\\n\", pat)\n",
    "#     pprint.pp(sorted(timm.list_models(pat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f64e6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-25T21:36:08.558363Z",
     "iopub.status.busy": "2025-09-25T21:36:08.558088Z",
     "iopub.status.idle": "2025-09-25T21:36:10.269648Z",
     "shell.execute_reply": "2025-09-25T21:36:10.268752Z"
    },
    "papermill": {
     "duration": 1.720474,
     "end_time": "2025-09-25T21:36:10.271470",
     "exception": false,
     "start_time": "2025-09-25T21:36:08.550996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from scipy import ndimage\n",
    "import warnings\n",
    "import gc\n",
    "from time import time\n",
    "from tqdm.auto import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class DICOMPreprocessorKaggle:\n",
    "    \"\"\"\n",
    "    DICOM preprocessing that converts original \n",
    "    DICOMPreprocessor logic to single series processing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_shape: Tuple[int, int, int] = (32, 384, 384)):\n",
    "        self.target_depth, self.target_height, self.target_width = target_shape\n",
    "        \n",
    "    def load_dicom_series(self, series_path: str) -> Tuple[List[pydicom.Dataset], str]:\n",
    "        \"\"\"\n",
    "        Load DICOM series\n",
    "        \"\"\"\n",
    "        series_path = Path(series_path)\n",
    "        series_name = series_path.name\n",
    "        \n",
    "        # Search for DICOM files\n",
    "        dicom_files = []\n",
    "        for root, _, files in os.walk(series_path):\n",
    "            for file in files:\n",
    "                if file.endswith('.dcm'):\n",
    "                    dicom_files.append(os.path.join(root, file))\n",
    "        \n",
    "        if not dicom_files:\n",
    "            raise ValueError(f\"No DICOM files found in {series_path}\")\n",
    "        \n",
    "        #print(f\"Found {len(dicom_files)} DICOM files in series {series_name}\")\n",
    "        \n",
    "        # Load DICOM datasets\n",
    "        datasets = []\n",
    "        for filepath in dicom_files:\n",
    "            try:\n",
    "                ds = pydicom.dcmread(filepath, force=True)\n",
    "                datasets.append(ds)\n",
    "            except Exception as e:\n",
    "                #print(f\"Failed to load {filepath}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not datasets:\n",
    "            raise ValueError(f\"No valid DICOM files in {series_path}\")\n",
    "        \n",
    "        return datasets, series_name\n",
    "    \n",
    "    def extract_slice_info(self, datasets: List[pydicom.Dataset]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Extract position information for each slice\n",
    "        \"\"\"\n",
    "        slice_info = []\n",
    "        \n",
    "        for i, ds in enumerate(datasets):\n",
    "            info = {\n",
    "                'dataset': ds,\n",
    "                'index': i,\n",
    "                'instance_number': getattr(ds, 'InstanceNumber', i),\n",
    "            }\n",
    "            \n",
    "            # Get z-coordinate from ImagePositionPatient\n",
    "            try:\n",
    "                position = getattr(ds, 'ImagePositionPatient', None)\n",
    "                if position is not None and len(position) >= 3:\n",
    "                    info['z_position'] = float(position[2])\n",
    "                else:\n",
    "                    # Fallback: use InstanceNumber\n",
    "                    info['z_position'] = float(info['instance_number'])\n",
    "                    #print(\"ImagePositionPatient not found, using InstanceNumber\")\n",
    "            except Exception as e:\n",
    "                info['z_position'] = float(i)\n",
    "                #print(f\"Failed to extract position info: {e}\")\n",
    "            \n",
    "            slice_info.append(info)\n",
    "        \n",
    "        return slice_info\n",
    "    \n",
    "    def sort_slices_by_position(self, slice_info: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Sort slices by z-coordinate\n",
    "        \"\"\"\n",
    "        # Sort by z-coordinate\n",
    "        sorted_slices = sorted(slice_info, key=lambda x: x['z_position'])\n",
    "        \n",
    "        #print(f\"Sorted {len(sorted_slices)} slices by z-position\")\n",
    "        #print(f\"Z-range: {sorted_slices[0]['z_position']:.2f} to {sorted_slices[-1]['z_position']:.2f}\")\n",
    "        \n",
    "        return sorted_slices\n",
    "    \n",
    "    def get_windowing_params(self, ds: pydicom.Dataset, img: np.ndarray = None) -> Tuple[Optional[float], Optional[float]]:\n",
    "        \"\"\"\n",
    "        Return (center, width) for windowing if appropriate, else (None, None).\n",
    "        For CTA/CT we use a fixed angiography window; for MR we skip windowing.\n",
    "        \"\"\"\n",
    "        modality = str(getattr(ds, \"Modality\", \"CT\")).upper()\n",
    "    \n",
    "        if modality == \"CT\":\n",
    "            # CTA-style windowing for vessels\n",
    "            center, width = 50.0, 350.0\n",
    "            return center, width\n",
    "    \n",
    "        # MR and other modalities: do percentile-based normalization downstream\n",
    "        return None, None\n",
    "\n",
    "    \n",
    "    def apply_windowing_or_normalize(self, img: np.ndarray, center: Optional[float], width: Optional[float]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        If (center,width) provided -> apply window to 0-255.\n",
    "        Else -> robust percentile normalization to 0-255.\n",
    "        Returns uint8.\n",
    "        \"\"\"\n",
    "        if center is not None and width is not None:\n",
    "            # CT/CTA windowing\n",
    "            img_min = center - width / 2.0\n",
    "            img_max = center + width / 2.0\n",
    "            windowed = np.clip(img, img_min, img_max)\n",
    "            windowed = (windowed - img_min) / max(1e-6, (img_max - img_min))\n",
    "            return (windowed * 255.0).astype(np.uint8)\n",
    "    \n",
    "        # MR (or unknown) -> percentile normalization\n",
    "        p1, p99 = np.percentile(img, [1, 99])\n",
    "        if p99 > p1:\n",
    "            norm = np.clip(img, p1, p99)\n",
    "            norm = (norm - p1) / (p99 - p1)\n",
    "            return (norm * 255.0).astype(np.uint8)\n",
    "    \n",
    "        # Fallback: min-max\n",
    "        mn, mx = float(img.min()), float(img.max())\n",
    "        if mx > mn:\n",
    "            norm = (img - mn) / (mx - mn)\n",
    "            return (norm * 255.0).astype(np.uint8)\n",
    "        return np.zeros_like(img, dtype=np.uint8)\n",
    "\n",
    "    \n",
    "    def extract_pixel_array(self, ds: pydicom.Dataset) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract 2D pixel array from DICOM and apply basic preprocessing.\n",
    "        Returns float32 image (no scaling to 0–255 here).\n",
    "        \"\"\"\n",
    "        # Raw pixel data to float32\n",
    "        img = ds.pixel_array.astype(np.float32)\n",
    "    \n",
    "        # If multi-frame (3D in a single file), take the middle frame for 2D path\n",
    "        if img.ndim == 3:\n",
    "            frame_idx = img.shape[0] // 2\n",
    "            img = img[frame_idx]\n",
    "    \n",
    "        # Handle MONOCHROME1 (invert): larger values are darker -> flip\n",
    "        if getattr(ds, \"PhotometricInterpretation\", \"\").upper() == \"MONOCHROME1\":\n",
    "            # Invert relative to full range to preserve dynamic range\n",
    "            img = img.max() - img\n",
    "    \n",
    "        # Apply DICOM rescale (DO NOT override slope/intercept)\n",
    "        slope = float(getattr(ds, \"RescaleSlope\", 1.0))\n",
    "        intercept = float(getattr(ds, \"RescaleIntercept\", 0.0))\n",
    "        if slope != 1.0 or intercept != 0.0:\n",
    "            img = img * slope + intercept\n",
    "    \n",
    "        # Optional: mask out pixel padding value if present (common in CT)\n",
    "        if hasattr(ds, \"PixelPaddingValue\"):\n",
    "            ppv = float(ds.PixelPaddingValue)\n",
    "            img = np.where(np.isclose(img, ppv), np.nan, img)\n",
    "    \n",
    "        # Replace NaNs introduced by padding with local minimum (keeps dtype)\n",
    "        if np.isnan(img).any():\n",
    "            # Use finite min; if all NaN (shouldn't happen), fill zeros\n",
    "            finite = img[np.isfinite(img)]\n",
    "            fill_val = finite.min() if finite.size else 0.0\n",
    "            img = np.nan_to_num(img, nan=fill_val)\n",
    "    \n",
    "        return img  # float32\n",
    "\n",
    "    \n",
    "    def resize_volume_3d(self, volume: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Resize 3D volume to target size\n",
    "        \"\"\"\n",
    "        current_shape = volume.shape\n",
    "        target_shape = (self.target_depth, self.target_height, self.target_width)\n",
    "        \n",
    "        if current_shape == target_shape:\n",
    "            return volume\n",
    "        \n",
    "        #print(f\"Resizing volume from {current_shape} to {target_shape}\")\n",
    "        \n",
    "        # 3D resizing using scipy.ndimage\n",
    "        zoom_factors = [\n",
    "            target_shape[i] / current_shape[i] for i in range(3)\n",
    "        ]\n",
    "        \n",
    "        # Resize with linear interpolation\n",
    "        resized_volume = ndimage.zoom(volume, zoom_factors, order=1, mode='nearest')\n",
    "        \n",
    "        # Clip to exact size just in case\n",
    "        resized_volume = resized_volume[:self.target_depth, :self.target_height, :self.target_width]\n",
    "        \n",
    "        # Padding if necessary\n",
    "        pad_width = [\n",
    "            (0, max(0, self.target_depth - resized_volume.shape[0])),\n",
    "            (0, max(0, self.target_height - resized_volume.shape[1])),\n",
    "            (0, max(0, self.target_width - resized_volume.shape[2]))\n",
    "        ]\n",
    "        \n",
    "        if any(pw[1] > 0 for pw in pad_width):\n",
    "            resized_volume = np.pad(resized_volume, pad_width, mode='edge')\n",
    "        \n",
    "        #print(f\"Final volume shape: {resized_volume.shape}\")\n",
    "        return resized_volume.astype(np.uint8)\n",
    "    \n",
    "    def process_series(self, series_path: str, return_meta: bool = False):\n",
    "        \"\"\"\n",
    "        Process DICOM series and return resampled NumPy array.\n",
    "        If return_meta=True, also returns a dict with:\n",
    "            - 'orig_depth': int, number of source slices/frames\n",
    "            - 'spacing':   tuple (dz, dy, dx) if available, else None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 1) Load DICOM files (headers + pixels on demand)\n",
    "            datasets, series_name = self.load_dicom_series(series_path)\n",
    "    \n",
    "            # --- compute orig_depth from headers, BEFORE resampling ---\n",
    "            orig_depth = None\n",
    "            dz = dy = dx = None\n",
    "    \n",
    "            if len(datasets) == 1:\n",
    "                ds0 = datasets[0]\n",
    "                # multiframe (enhanced) 3D?\n",
    "                nframes = getattr(ds0, \"NumberOfFrames\", None)\n",
    "                if nframes is not None:\n",
    "                    try:\n",
    "                        orig_depth = int(nframes)\n",
    "                    except Exception:\n",
    "                        orig_depth = None\n",
    "                # if not set, try pixel array ndim==3\n",
    "                if orig_depth is None:\n",
    "                    try:\n",
    "                        arr0 = ds0.pixel_array  # pydicom will decode\n",
    "                        if arr0.ndim == 3:\n",
    "                            orig_depth = int(arr0.shape[0])\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            else:\n",
    "                # multiple single-slice files: count unique z positions if possible\n",
    "                z_vals = []\n",
    "                for ds in datasets:\n",
    "                    ipp = getattr(ds, \"ImagePositionPatient\", None)\n",
    "                    iop = getattr(ds, \"ImageOrientationPatient\", None)\n",
    "                    if ipp is not None and iop is not None and len(ipp) == 3 and len(iop) >= 6:\n",
    "                        # Quick proxy: use z = IPP[2]\n",
    "                        z_vals.append(float(ipp[2]))\n",
    "                    else:\n",
    "                        sl = getattr(ds, \"SliceLocation\", None)\n",
    "                        if sl is not None:\n",
    "                            z_vals.append(float(sl))\n",
    "                if z_vals:\n",
    "                    orig_depth = int(np.unique(np.round(z_vals, 5)).size)\n",
    "                if orig_depth is None:\n",
    "                    # fallback: number of DICOM files\n",
    "                    orig_depth = len(datasets)\n",
    "    \n",
    "            # optional spacing (best-effort)\n",
    "            try:\n",
    "                # dy, dx from PixelSpacing; dz from SpacingBetweenSlices or SliceThickness\n",
    "                ds_ref = datasets[0]\n",
    "                px = getattr(ds_ref, \"PixelSpacing\", None)  # [dy, dx]\n",
    "                dy = float(px[0]) if px is not None else None\n",
    "                dx = float(px[1]) if px is not None else None\n",
    "                dz = getattr(ds_ref, \"SpacingBetweenSlices\", None)\n",
    "                dz = float(dz) if dz is not None else None\n",
    "                if dz is None:\n",
    "                    st = getattr(ds_ref, \"SliceThickness\", None)\n",
    "                    dz = float(st) if st is not None else None\n",
    "            except Exception:\n",
    "                dz = dy = dx = None\n",
    "    \n",
    "            # 2) Produce the resampled volume (your existing logic)\n",
    "            first_ds = datasets[0]\n",
    "            first_img = first_ds.pixel_array\n",
    "    \n",
    "            if len(datasets) == 1 and first_img.ndim == 3:\n",
    "                vol = self._process_single_3d_dicom(first_ds, series_name)  # (32,H,W) float/uint8\n",
    "            else:\n",
    "                vol = self._process_multiple_2d_dicoms(datasets, series_name)  # (32,H,W)\n",
    "    \n",
    "            if return_meta:\n",
    "                return vol, {\"orig_depth\": int(orig_depth) if orig_depth is not None else None,\n",
    "                             \"spacing\": (dz, dy, dx) if (dz is not None and dy is not None and dx is not None) else None}\n",
    "            return vol\n",
    "    \n",
    "        except Exception:\n",
    "            raise\n",
    "\n",
    "    \n",
    "    def _process_single_3d_dicom(self, ds: pydicom.Dataset, series_name: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Process single 3D DICOM file (for Kaggle: no file saving)\n",
    "        \"\"\"\n",
    "        # Get pixel array\n",
    "        volume = ds.pixel_array.astype(np.float32)\n",
    "        \n",
    "        # Apply RescaleSlope and RescaleIntercept\n",
    "        slope = float(getattr(ds, \"RescaleSlope\", 1.0))\n",
    "        intercept = float(getattr(ds, \"RescaleIntercept\", 0.0))\n",
    "        if slope != 1.0 or intercept != 0.0:\n",
    "            volume = volume * slope + intercept\n",
    "            # #print(f\"Applied rescaling: slope={slope}, intercept={intercept}\")\n",
    "        \n",
    "        # Get windowing settings\n",
    "        window_center, window_width = self.get_windowing_params(ds)\n",
    "        \n",
    "        # Apply windowing to each slice\n",
    "        processed_slices = []\n",
    "        for i in range(volume.shape[0]):\n",
    "            slice_img = volume[i]\n",
    "            processed_img = self.apply_windowing_or_normalize(slice_img, window_center, window_width)\n",
    "            processed_slices.append(processed_img)\n",
    "        \n",
    "        volume = np.stack(processed_slices, axis=0)\n",
    "        ##print(f\"3D volume shape after windowing: {volume.shape}\")\n",
    "        \n",
    "        # 3D resize\n",
    "        final_volume = self.resize_volume_3d(volume)\n",
    "        \n",
    "        ##print(f\"Successfully processed 3D DICOM series {series_name}\")\n",
    "        return final_volume\n",
    "    \n",
    "    def _process_multiple_2d_dicoms(self, datasets: List[pydicom.Dataset], series_name: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Process multiple 2D DICOM files (for Kaggle: no file saving)\n",
    "        \"\"\"\n",
    "        slice_info = self.extract_slice_info(datasets)\n",
    "        sorted_slices = self.sort_slices_by_position(slice_info)\n",
    "        first_img = self.extract_pixel_array(sorted_slices[0]['dataset'])\n",
    "        window_center, window_width = self.get_windowing_params(sorted_slices[0]['dataset'], first_img)\n",
    "        processed_slices = []\n",
    "        \n",
    "        for slice_data in sorted_slices:\n",
    "            ds = slice_data['dataset']\n",
    "            img = self.extract_pixel_array(ds)\n",
    "            processed_img = self.apply_windowing_or_normalize(img, window_center, window_width)\n",
    "            # resized_img = cv2.resize(processed_img, (self.target_width, self.target_height), interpolation=cv2.INTER_AREA)\n",
    "            resized_img = cv2.resize(processed_img, (self.target_width, self.target_height), interpolation=cv2.INTER_LINEAR)\n",
    "            \n",
    "            processed_slices.append(resized_img)\n",
    "\n",
    "        volume = np.stack(processed_slices, axis=0)\n",
    "        ##print(f\"2D slices stacked to volume shape: {volume.shape}\")\n",
    "        final_volume = self.resize_volume_3d(volume)\n",
    "        \n",
    "        ##print(f\"Successfully processed 2D DICOM series {series_name}\")\n",
    "        return final_volume\n",
    "\n",
    "def process_dicom_series_kaggle(series_path: str, target_shape: Tuple[int, int, int] = (32, 384, 384)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    DICOM processing function for Kaggle inference (single series)\n",
    "    \n",
    "    Args:\n",
    "        series_path: Path to DICOM series\n",
    "        target_shape: Target volume size (depth, height, width)\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Processed volume\n",
    "    \"\"\"\n",
    "    preprocessor = DICOMPreprocessorKaggle(target_shape=target_shape)\n",
    "    return preprocessor.process_series(series_path)\n",
    "\n",
    "# Safe processing function with memory cleanup\n",
    "def process_dicom_series_safe(series_path: str, target_shape: Tuple[int, int, int] = (32, 384, 384)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Safe DICOM processing with memory cleanup\n",
    "    \n",
    "    Args:\n",
    "        series_path: Path to DICOM series\n",
    "        target_shape: Target volume size (depth, height, width)\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Processed volume\n",
    "    \"\"\"\n",
    "    try:\n",
    "        volume = process_dicom_series_kaggle(series_path, target_shape)\n",
    "        return volume\n",
    "    finally:\n",
    "        # Memory cleanup\n",
    "        gc.collect()\n",
    "\n",
    "# Test function\n",
    "def test_single_series(series_path: str, target_shape: Tuple[int, int, int] = (32, 384, 384)):\n",
    "    \"\"\"\n",
    "    Test processing for single series\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #print(f\"Testing single series: {series_path}\")\n",
    "        \n",
    "        # Execute processing\n",
    "        volume = process_dicom_series_safe(series_path, target_shape)\n",
    "        \n",
    "        # Display results\n",
    "        #print(f\"Successfully processed series\")\n",
    "        #print(f\"Volume shape: {volume.shape}\")\n",
    "        #print(f\"Volume dtype: {volume.dtype}\")\n",
    "        #print(f\"Volume range: [{volume.min()}, {volume.max()}]\")\n",
    "        \n",
    "        return volume\n",
    "        \n",
    "    except Exception as e:\n",
    "        #print(f\"Failed to process series: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c361382b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T21:36:10.283914Z",
     "iopub.status.busy": "2025-09-25T21:36:10.283418Z",
     "iopub.status.idle": "2025-09-25T21:36:15.287030Z",
     "shell.execute_reply": "2025-09-25T21:36:15.286084Z"
    },
    "papermill": {
     "duration": 5.011539,
     "end_time": "2025-09-25T21:36:15.288647",
     "exception": false,
     "start_time": "2025-09-25T21:36:10.277108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  DDP / AMP helpers\n",
    "\n",
    "import os\n",
    "import torch.distributed as dist\n",
    "\n",
    "def get_dist_env():\n",
    "    \"\"\"Read torchrun/torch.distributed env with safe defaults.\"\"\"\n",
    "    local_rank = int(os.environ.get(\"LOCAL_RANK\", os.environ.get(\"SLURM_LOCALID\", 0)))\n",
    "    rank       = int(os.environ.get(\"RANK\", 0))\n",
    "    world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "    return local_rank, rank, world_size\n",
    "\n",
    "def setup_distributed():\n",
    "    local_rank, rank, world_size = get_dist_env()\n",
    "    is_distributed = world_size > 1\n",
    "    if is_distributed and not dist.is_initialized():\n",
    "        dist.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "        torch.cuda.set_device(local_rank)\n",
    "    return local_rank, rank, world_size, is_distributed\n",
    "\n",
    "def cleanup_distributed():\n",
    "    if dist.is_available() and dist.is_initialized():\n",
    "        dist.barrier()\n",
    "        dist.destroy_process_group()\n",
    "\n",
    "def is_main_process():\n",
    "    return int(os.environ.get(\"RANK\", 0)) == 0\n",
    "\n",
    "def seed_everything(base_seed=42):\n",
    "    # different seed per rank for true shuffling; still reproducible\n",
    "    _, rank, _ = get_dist_env()\n",
    "    seed = base_seed + rank\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    return seed\n",
    "\n",
    "def scale_lr_for_world_size(lr: float):\n",
    "    \"\"\"Linear LR scaling (per-GPU batch fixed, total batch = world_size * perGPU).\"\"\"\n",
    "    _, _, world_size = get_dist_env()\n",
    "    return lr * max(1, world_size)\n",
    "\n",
    "# Optional toggles you can use elsewhere\n",
    "USE_CHANNELS_LAST = True     # improves throughput on T4 with AMP\n",
    "USE_TORCH_COMPILE = False     # try torch.compile; fall back if it errors\n",
    "AMP_DTYPE = \"bf16\"           # T4 → fp16; (A100/H100 can use \"bf16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528bc1b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T21:36:15.301957Z",
     "iopub.status.busy": "2025-09-25T21:36:15.301164Z",
     "iopub.status.idle": "2025-09-25T21:36:29.324093Z",
     "shell.execute_reply": "2025-09-25T21:36:29.323030Z"
    },
    "papermill": {
     "duration": 14.031513,
     "end_time": "2025-09-25T21:36:29.325868",
     "exception": false,
     "start_time": "2025-09-25T21:36:15.294355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Config & labels \n",
    "import os, math, json, random, copy\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import timm\n",
    "\n",
    "# Label order must match competition columns\n",
    "LABEL_COLS = [\n",
    "    \"Left Infraclinoid Internal Carotid Artery\",\n",
    "    \"Right Infraclinoid Internal Carotid Artery\",\n",
    "    \"Left Supraclinoid Internal Carotid Artery\",\n",
    "    \"Right Supraclinoid Internal Carotid Artery\",\n",
    "    \"Left Middle Cerebral Artery\",\n",
    "    \"Right Middle Cerebral Artery\",\n",
    "    \"Anterior Communicating Artery\",\n",
    "    \"Left Anterior Cerebral Artery\",\n",
    "    \"Right Anterior Cerebral Artery\",\n",
    "    \"Left Posterior Communicating Artery\",\n",
    "    \"Right Posterior Communicating Artery\",\n",
    "    \"Basilar Tip\",\n",
    "    \"Other Posterior Circulation\",\n",
    "    \"Aneurysm Present\",\n",
    "]\n",
    "ANEURYSM_PRESENT_IDX = 13\n",
    "\n",
    "@dataclass\n",
    "class CFG:\n",
    "    series_root: str = r\"D:/User Data/Downloads/rsna-intracranial-aneurysm-detection/series\"\n",
    "    train_csv: str  = r\"D:/User Data/Downloads/rsna-intracranial-aneurysm-detection/train.csv\"\n",
    "    localizers_csv_path: str = r\"D:/User Data/Downloads/rsna-intracranial-aneurysm-detection/train_localizers.csv\"\n",
    "\n",
    "    img_size: int = 384\n",
    "    base_slices: int = 32\n",
    "    extra_cached_chans: int = 0\n",
    "    use_vessel_sidecar: bool = True\n",
    "    vessel_sidecar_mode: str = \"mip\"\n",
    "    vessel_extra: int = 1 if (use_vessel_sidecar and vessel_sidecar_mode == \"mip\") else (32 if (use_vessel_sidecar and vessel_sidecar_mode == \"per_slice\") else 0)\n",
    "    use_localizers: bool = True\n",
    "    max_localizer_crops: int = 3\n",
    "    \n",
    "    local_crop_size: int = 128\n",
    "    p_localizer_dropout: float = 0.30\n",
    "    # optional: occasionally turn localizers fully off\n",
    "    p_global_localizer_off: float = 0.10\n",
    "\n",
    "    num_classes: int = 14\n",
    "    model_name: str = \"maxvit_base_tf_384\"\n",
    "    epochs: int = 34\n",
    "    batch_size: int = 2\n",
    "    num_workers: int = 2\n",
    "    lr: float = 1.6e-4\n",
    "    weight_decay: float = 0.05\n",
    "    warmup_epochs: float = 5.0\n",
    "    min_lr: float = 3e-6\n",
    "    clip_grad_norm: float = 1.0\n",
    "    use_amp: bool = True\n",
    "    label_smoothing: float = 0.02\n",
    "    focal_loss: bool = False\n",
    "    focal_gamma: float = 1.5\n",
    "    pos_weight: float = 1.0\n",
    "    folds: int = 5\n",
    "    seed: int = 42\n",
    "    out_dir: str = \"./outputs\"\n",
    "    save_name: str = \"maxvitbasemodel\"\n",
    "    seeds: list = field(default_factory=lambda: [42, 2025, 8])\n",
    "\n",
    "    # computed after init\n",
    "    in_chans: int = base_slices + extra_cached_chans + max_localizer_crops + vessel_extra \n",
    "    # in_chans: int = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        k = self.max_localizer_crops if self.use_localizers else 0\n",
    "        self.in_chans = self.base_slices + self.extra_cached_chans + k\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "\n",
    "def per_label_auc(y_true: np.ndarray, y_prob: np.ndarray) -> Dict[str, float]:\n",
    "    out = {}\n",
    "    for i, name in enumerate(LABEL_COLS):\n",
    "        yi, pi = y_true[:, i], y_prob[:, i]\n",
    "        out[name] = roc_auc_score(yi, pi) if len(np.unique(yi)) >= 2 else np.nan\n",
    "    return out\n",
    "\n",
    "def comp_weighted_auc(aucs: Dict[str, float]) -> float:\n",
    "    weights, vals = [], []\n",
    "    for i, name in enumerate(LABEL_COLS):\n",
    "        w = 13.0 if i == ANEURYSM_PRESENT_IDX else 1.0\n",
    "        if not np.isnan(aucs[name]):\n",
    "            weights.append(w); vals.append(aucs[name]*w)\n",
    "    return (sum(vals)/sum(weights)) if weights else np.nan\n",
    "\n",
    "def cfg_to_dict(cfg_cls) -> dict:\n",
    "    return {\n",
    "        k: getattr(cfg_cls, k) \n",
    "        for k in dir(cfg_cls)\n",
    "        if not k.startswith(\"__\") and not callable(getattr(cfg_cls, k))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a555d",
   "metadata": {
    "papermill": {
     "duration": 0.005341,
     "end_time": "2025-09-25T21:36:29.336949",
     "exception": false,
     "start_time": "2025-09-25T21:36:29.331608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cacheing via shards\n",
    "Strategy\n",
    "\n",
    "Shard the cache into folders/files ≤ ~5–8 GB each (safe margin).\n",
    "\n",
    "In each Kaggle run, build one shard in /kaggle/working/shard_k/…, then:\n",
    "\n",
    "Option A: leave as plain .npy files inside shard folder.\n",
    "\n",
    "Option B (nice for scale): pack into WebDataset tar shards (.tar with simple naming).\n",
    "\n",
    "Download the shard (or “Commit & Save Output”) and upload as a Kaggle Dataset (either one dataset with many files or multiple versions).\n",
    "\n",
    "In your training notebook, Add Data → select your dataset(s). They’ll appear under /kaggle/input/<your-dataset>/… (no 20 GB limit).\n",
    "\n",
    "Your DataLoader reads from /kaggle/input paths (mmap .npy or stream tar shards)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e323f65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T21:36:29.349574Z",
     "iopub.status.busy": "2025-09-25T21:36:29.349228Z",
     "iopub.status.idle": "2025-09-25T21:36:29.355278Z",
     "shell.execute_reply": "2025-09-25T21:36:29.354479Z"
    },
    "papermill": {
     "duration": 0.014456,
     "end_time": "2025-09-25T21:36:29.356853",
     "exception": false,
     "start_time": "2025-09-25T21:36:29.342397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# import os, math, hashlib, numpy as np, pandas as pd, time, multiprocessing as mp\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# # Prevent oversubscription (each worker will do BLAS/ndimage work)\n",
    "# os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "# os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "# os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "# os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")\n",
    "\n",
    "# IMG_SIZE      = CFG.img_size      # 384 to preserve quality (or 320)\n",
    "# BYTES_PER_ELT = 1                 # uint8\n",
    "# DEPTH         = 32\n",
    "# TARGET_BYTES_PER_SHARD = 6 * 1024**3\n",
    "# OUT_BASE = f\"/kaggle/working/cache_u8_{IMG_SIZE}\"\n",
    "\n",
    "# # Choose which shard to build in THIS run:\n",
    "# NUM_SHARDS   = None   # None = auto-compute\n",
    "# SHARD_ID     = 3      # change per run\n",
    "# NUM_WORKERS  = max(1, mp.cpu_count()-1)  \n",
    "\n",
    "# df_all = pd.read_csv(CFG.train_csv)\n",
    "# df_all = df_all[df_all[\"SeriesInstanceUID\"].apply(\n",
    "#     lambda u: os.path.isdir(os.path.join(CFG.series_root, str(u)))\n",
    "# )].reset_index(drop=True)\n",
    "\n",
    "# bytes_per_series = DEPTH * IMG_SIZE * IMG_SIZE * BYTES_PER_ELT\n",
    "# est_total_bytes  = len(df_all) * bytes_per_series\n",
    "# if NUM_SHARDS is None:\n",
    "#     NUM_SHARDS = max(1, math.ceil(est_total_bytes / TARGET_BYTES_PER_SHARD))\n",
    "\n",
    "# print(f\"[Shard plan] ~{est_total_bytes/1e9:.2f} GB total, \"\n",
    "#       f\"~{TARGET_BYTES_PER_SHARD/1e9:.1f} GB per shard → NUM_SHARDS={NUM_SHARDS}\")\n",
    "# assert 0 <= SHARD_ID < NUM_SHARDS, \"Set SHARD_ID within [0, NUM_SHARDS)\"\n",
    "\n",
    "# def sid_to_shard(sid: str, num_shards: int) -> int:\n",
    "#     h = int(hashlib.md5(sid.encode(\"utf-8\")).hexdigest()[:8], 16)\n",
    "#     return h % num_shards\n",
    "\n",
    "# df_shard = df_all[df_all[\"SeriesInstanceUID\"].astype(str).map(\n",
    "#     lambda s: sid_to_shard(s, NUM_SHARDS) == SHARD_ID\n",
    "# )].reset_index(drop=True)\n",
    "# print(f\"[Shard {SHARD_ID}/{NUM_SHARDS}] series: {len(df_shard)}\")\n",
    "\n",
    "# OUT_DIR = f\"{OUT_BASE}_shard{SHARD_ID:02d}\"\n",
    "# os.makedirs(OUT_DIR, exist_ok=True)\n",
    "# print(\"Output dir:\", OUT_DIR)\n",
    "\n",
    "# def cache_path_for(sid: str) -> str:\n",
    "#     return os.path.join(OUT_DIR, f\"{sid}_{IMG_SIZE}.npy\")\n",
    "\n",
    "# sids_all = df_shard[\"SeriesInstanceUID\"].astype(str).tolist()\n",
    "# to_write = [sid for sid in sids_all if not os.path.exists(cache_path_for(sid))]\n",
    "# to_skip  = len(sids_all) - len(to_write)\n",
    "# print(f\"Will save: {len(to_write)}  |  Already cached (skip): {to_skip}\")\n",
    "\n",
    "# # Worker function (creates its own preprocessor)\n",
    "# def _worker(sid):\n",
    "#     try:\n",
    "#         from __main__ import DICOMPreprocessorKaggle, CFG\n",
    "#         preproc = DICOMPreprocessorKaggle(target_shape=(DEPTH, IMG_SIZE, IMG_SIZE))\n",
    "#         vol, meta = preproc.process_series(os.path.join(CFG.series_root, sid), return_meta=True)\n",
    "#         if vol.dtype != np.uint8:\n",
    "#             vol = np.clip(vol, 0, 255).astype(np.uint8)\n",
    "#         np.save(cache_path_for(sid), vol, allow_pickle=False)\n",
    "#         return (sid, int(meta.get('orig_depth') or 32), True, None)\n",
    "#     except Exception as e:\n",
    "#         return (sid, None, False, str(e))\n",
    "\n",
    "\n",
    "# t0 = time.time()\n",
    "\n",
    "# # Collect results from workers\n",
    "# results = []\n",
    "# ok, err = 0, 0\n",
    "# with mp.Pool(processes=NUM_WORKERS) as pool, tqdm(total=len(to_write), unit=\"series\",\n",
    "#                                                   desc=f\"Shard {SHARD_ID} @ {IMG_SIZE}px\") as pbar:\n",
    "#     for sid, orig_depth, success, error_msg in pool.imap_unordered(_worker, to_write, chunksize=2):\n",
    "#         results.append((sid, orig_depth, success, error_msg))\n",
    "#         if success: ok += 1\n",
    "#         else: err += 1\n",
    "#         pbar.update(1)\n",
    "\n",
    "# # Build manifest rows: include both processed and skipped\n",
    "# rows = []\n",
    "\n",
    "# # 1) Add processed results\n",
    "# for sid, orig_depth, success, error_msg in results:\n",
    "#     rows.append({\n",
    "#         \"SeriesInstanceUID\": sid,\n",
    "#         \"img_size\": IMG_SIZE,\n",
    "#         \"cache_path\": cache_path_for(sid),\n",
    "#         \"orig_depth\": orig_depth,\n",
    "#         \"skipped\": False,\n",
    "#         \"success\": bool(success),\n",
    "#         \"error\": (None if success else (str(error_msg) if error_msg is not None else \"unknown\"))\n",
    "#     })\n",
    "\n",
    "# # 2) Add skipped (already cached) entries so the manifest is complete\n",
    "# skipped_sids = [sid for sid in sids_all if sid not in set(to_write)]\n",
    "# for sid in skipped_sids:\n",
    "#     rows.append({\n",
    "#         \"SeriesInstanceUID\": sid,\n",
    "#         \"img_size\": IMG_SIZE,\n",
    "#         \"cache_path\": cache_path_for(sid),\n",
    "#         \"orig_depth\": None,   # unknown because we didn't reprocess; can be filled later if you have it\n",
    "#         \"skipped\": True,\n",
    "#         \"success\": True,\n",
    "#         \"error\": None\n",
    "#     })\n",
    "\n",
    "# # Save manifest as Parquet in the shard folder\n",
    "# manifest_path = os.path.join(OUT_DIR, f\"manifest_{IMG_SIZE}.parquet\")\n",
    "# pd.DataFrame(rows).to_parquet(manifest_path, index=False)\n",
    "# print(f\"Manifest saved: {manifest_path}\")\n",
    "\n",
    "# dt = time.time() - t0\n",
    "# print(f\"[Shard {SHARD_ID}] saved: {ok}, skipped: {to_skip}, errors: {err}, \"\n",
    "#       f\"elapsed: {dt/60:.1f} min (~{(dt/max(1, max(ok,1))):0.2f}s/series)\")\n",
    "# print(\"Shard folder is ready to download or save as Notebook Output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =============================\n",
    "# # Cache vs Raw Preprocessing Check\n",
    "# # =============================\n",
    "# import os, random, math, numpy as np, pandas as pd\n",
    "# from pathlib import Path\n",
    "# from typing import List, Optional, Tuple\n",
    "# from tqdm.auto import tqdm\n",
    "# import glob\n",
    "\n",
    "# # --- reuse your cache discovery helpers ---\n",
    "# def discover_shard_roots_for(img_size: int) -> List[str]:\n",
    "#     SHARDS_ROOT = \"/kaggle/input/shards\"\n",
    "#     pattern = os.path.join(SHARDS_ROOT, \"*\", f\"cache_u8_{img_size}_shard*\")\n",
    "#     roots = sorted([p for p in glob.glob(pattern) if os.path.isdir(p)])\n",
    "#     if is_main_process():\n",
    "#         print(f\"Found {len(roots)} shard roots for {img_size}px\")\n",
    "#     return roots\n",
    "\n",
    "# def make_find_cached_path(shard_roots: List[str]):\n",
    "#     def _find_cached_path(sid: str, img_size: int) -> Optional[str]:\n",
    "#         fname = f\"{sid}_{img_size}.npy\"\n",
    "#         for root in shard_roots:\n",
    "#             p = os.path.join(root, fname)\n",
    "#             if os.path.exists(p):\n",
    "#                 return p\n",
    "#         return None\n",
    "#     return _find_cached_path\n",
    "\n",
    "# def _psnr_u8(a: np.ndarray, b: np.ndarray) -> float:\n",
    "#     # a, b uint8 arrays of same shape\n",
    "#     diff = a.astype(np.float32) - b.astype(np.float32)\n",
    "#     mse = float(np.mean(diff**2))\n",
    "#     if mse == 0: \n",
    "#         return float('inf')\n",
    "#     return 20.0 * math.log10(255.0) - 10.0 * math.log10(mse)\n",
    "\n",
    "# def _compare_pair(vol_cached_u8: np.ndarray, vol_raw_u8: np.ndarray) -> dict:\n",
    "#     assert vol_cached_u8.shape == vol_raw_u8.shape, f\"Shape mismatch {vol_cached_u8.shape} vs {vol_raw_u8.shape}\"\n",
    "#     assert vol_cached_u8.dtype == np.uint8 and vol_raw_u8.dtype == np.uint8\n",
    "\n",
    "#     a = vol_cached_u8\n",
    "#     b = vol_raw_u8\n",
    "\n",
    "#     mean_abs = float(np.mean(np.abs(a.astype(np.int16) - b.astype(np.int16))))\n",
    "#     max_abs  = int(np.max(np.abs(a.astype(np.int16) - b.astype(np.int16))))\n",
    "#     eq_rate  = float(np.mean(a == b))\n",
    "#     psnr     = _psnr_u8(a, b)\n",
    "\n",
    "#     # also compare after scaling to [0,1] like training input\n",
    "#     a01 = a.astype(np.float32) / 255.0\n",
    "#     b01 = b.astype(np.float32) / 255.0\n",
    "#     mae01 = float(np.mean(np.abs(a01 - b01)))\n",
    "#     rmse01 = float(np.sqrt(np.mean((a01 - b01)**2)))\n",
    "\n",
    "#     return {\n",
    "#         \"mean_abs_u8\": mean_abs,\n",
    "#         \"max_abs_u8\":  max_abs,\n",
    "#         \"eq_rate\":     eq_rate,\n",
    "#         \"psnr_u8\":     psnr,\n",
    "#         \"mae_01\":      mae01,\n",
    "#         \"rmse_01\":     rmse01,\n",
    "#         \"min_cached\":  int(a.min()), \"max_cached\": int(a.max()),\n",
    "#         \"min_raw\":     int(b.min()), \"max_raw\":   int(b.max()),\n",
    "#     }\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def verify_cache_vs_raw(sample_n: int = 50, seed: int = 123, verbose: bool = True) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Compare cached u8 volumes vs on-the-fly preprocessor outputs.\n",
    "#     Returns a DataFrame with metrics per sampled SID.\n",
    "#     \"\"\"\n",
    "#     rng = random.Random(seed)\n",
    "\n",
    "#     # load list of available series\n",
    "#     df_all = pd.read_csv(CFG.train_csv)\n",
    "#     exists = df_all[\"SeriesInstanceUID\"].apply(lambda u: os.path.isdir(os.path.join(CFG.series_root, str(u))))\n",
    "#     df_all = df_all[exists].reset_index(drop=True)\n",
    "\n",
    "#     # cache resolver\n",
    "#     shard_roots = discover_shard_roots_for(CFG.img_size)\n",
    "#     find_cached_path = make_find_cached_path(shard_roots)\n",
    "\n",
    "#     # pick SIDs that have a cache file\n",
    "#     candidates = []\n",
    "#     for sid in df_all[\"SeriesInstanceUID\"].astype(str).tolist():\n",
    "#         cp = find_cached_path(sid, CFG.img_size)\n",
    "#         if cp is not None:\n",
    "#             candidates.append((sid, cp))\n",
    "\n",
    "#     if len(candidates) == 0:\n",
    "#         raise RuntimeError(\"No cached files found; build cache first.\")\n",
    "\n",
    "#     if sample_n > len(candidates):\n",
    "#         sample_n = len(candidates)\n",
    "\n",
    "#     sample = rng.sample(candidates, sample_n)\n",
    "\n",
    "#     # instantiate preprocessor once (same as cache builder)\n",
    "#     preproc = DICOMPreprocessorKaggle(target_shape=(CFG.in_chans, CFG.img_size, CFG.img_size))\n",
    "\n",
    "#     rows = []\n",
    "#     for sid, cache_path in tqdm(sample, desc=\"Checking cache vs raw\", unit=\"series\"):\n",
    "#         # load cached\n",
    "#         vol_cached = np.load(cache_path, mmap_mode=\"r\")\n",
    "#         if vol_cached.dtype != np.uint8:\n",
    "#             vol_cached = np.clip(vol_cached, 0, 255).astype(np.uint8)\n",
    "\n",
    "#         # recompute raw\n",
    "#         series_path = os.path.join(CFG.series_root, sid)\n",
    "#         vol_raw = preproc.process_series(series_path)\n",
    "#         if vol_raw.dtype != np.uint8:\n",
    "#             vol_raw = np.clip(vol_raw, 0, 255).astype(np.uint8)\n",
    "\n",
    "#         # compare\n",
    "#         try:\n",
    "#             metrics = _compare_pair(vol_cached, vol_raw)\n",
    "#         except AssertionError as e:\n",
    "#             metrics = {\"error\": str(e)}\n",
    "\n",
    "#         row = {\"SeriesInstanceUID\": sid, **metrics}\n",
    "#         rows.append(row)\n",
    "\n",
    "#     df = pd.DataFrame(rows)\n",
    "\n",
    "#     if verbose:\n",
    "#         if \"error\" in df.columns:\n",
    "#             has_error = df[\"error\"].notna() & (df[\"error\"].astype(str).str.len() > 0)\n",
    "#         else:\n",
    "#             has_error = pd.Series(False, index=df.index)\n",
    "\n",
    "#         ok = df[~has_error]\n",
    "#         if len(ok):\n",
    "#             psnr_vals = ok[\"psnr_u8\"].replace(np.inf, 100.0) if \"psnr_u8\" in ok else pd.Series(dtype=float)\n",
    "#             print(\n",
    "#                 \"Summary (no-error rows): \"\n",
    "#                 f\"mean mean_abs_u8={ok['mean_abs_u8'].mean():.4f}, \"\n",
    "#                 f\"mean max_abs_u8={ok['max_abs_u8'].mean():.2f}, \"\n",
    "#                 f\"mean eq_rate={ok['eq_rate'].mean():.4f}, \"\n",
    "#                 f\"mean psnr_u8={psnr_vals.mean():.2f} dB, \"\n",
    "#                 f\"mean mae_01={ok['mae_01'].mean():.6f}, \"\n",
    "#                 f\"mean rmse_01={ok['rmse_01'].mean():.6f}\"\n",
    "#             )\n",
    "#         bad = df[has_error]\n",
    "#         if len(bad):\n",
    "#             print(f\"{len(bad)} series had shape/dtype errors; inspect df for details.\")\n",
    "\n",
    "#     return df\n",
    "\n",
    "# # ---- Run it (example) ----\n",
    "# df_check = verify_cache_vs_raw(sample_n=40, seed=42)\n",
    "# display(df_check.sort_values(\"mean_abs_u8\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d280295c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T21:36:29.369095Z",
     "iopub.status.busy": "2025-09-25T21:36:29.368805Z",
     "iopub.status.idle": "2025-09-25T21:36:29.380808Z",
     "shell.execute_reply": "2025-09-25T21:36:29.379881Z"
    },
    "papermill": {
     "duration": 0.019939,
     "end_time": "2025-09-25T21:36:29.382389",
     "exception": false,
     "start_time": "2025-09-25T21:36:29.362450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "import glob\n",
    "import ast\n",
    "\n",
    "def load_localizers_csv(csv_path: Optional[str], max_points_per_series: int = 3) -> Dict[str, List[dict]]:\n",
    "    \"\"\"\n",
    "    Load localizers with columns:\n",
    "      - SeriesInstanceUID\n",
    "      - SOPInstanceUID\n",
    "      - coordinates: string like \"{'x': 258.3, 'y': 261.4}\" or '{\"x\":..., \"y\":...}'\n",
    "      - location: optional text label\n",
    "\n",
    "    Returns: { sid: [ {'x': float|None, 'y': float|None, 'sop': str|None, 'loc': str|None}, ... ] }\n",
    "    \"\"\"\n",
    "    if not csv_path:\n",
    "        return {}\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # normalize column names\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    sid_col = cols.get('seriesinstanceuid') or 'SeriesInstanceUID'\n",
    "    sop_col = cols.get('sopinstanceuid') or 'SOPInstanceUID'\n",
    "    coord_col = cols.get('coordinates') or 'coordinates'\n",
    "    loc_col = cols.get('location') or ('Location' if 'Location' in df.columns else None)\n",
    "\n",
    "    keep = [c for c in [sid_col, sop_col, coord_col, loc_col] if c in df.columns]\n",
    "    df = df[keep].copy()\n",
    "\n",
    "    by_sid: Dict[str, List[dict]] = defaultdict(list)\n",
    "    for _, r in df.iterrows():\n",
    "        sid = str(r[sid_col])\n",
    "        sop = str(r[sop_col]) if sop_col in r and pd.notna(r[sop_col]) else None\n",
    "        loc = str(r[loc_col]) if loc_col and pd.notna(r[loc_col]) else None\n",
    "\n",
    "        x = y = None\n",
    "        if coord_col in r and pd.notna(r[coord_col]):\n",
    "            s = str(r[coord_col]).strip()\n",
    "            try:\n",
    "                # handle both single-quote and JSON strings\n",
    "                if s.startswith('{') and s.endswith('}'):\n",
    "                    xy = ast.literal_eval(s)\n",
    "                    x = float(xy.get('x')) if xy.get('x') is not None else None\n",
    "                    y = float(xy.get('y')) if xy.get('y') is not None else None\n",
    "            except Exception:\n",
    "                x = y = None\n",
    "\n",
    "        by_sid[sid].append({'x': x, 'y': y, 'sop': sop, 'loc': loc})\n",
    "\n",
    "    # cap per series\n",
    "    for sid in list(by_sid.keys()):\n",
    "        by_sid[sid] = by_sid[sid][:max_points_per_series]\n",
    "\n",
    "    return dict(by_sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4fb2bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T21:36:29.395580Z",
     "iopub.status.busy": "2025-09-25T21:36:29.395211Z",
     "iopub.status.idle": "2025-09-25T21:36:29.400890Z",
     "shell.execute_reply": "2025-09-25T21:36:29.400097Z"
    },
    "papermill": {
     "duration": 0.013821,
     "end_time": "2025-09-25T21:36:29.402258",
     "exception": false,
     "start_time": "2025-09-25T21:36:29.388437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def discover_shard_roots() -> List[str]:\n",
    "    \"\"\"Find all cache shard folders under /kaggle/input/shards/*/cache_u8_{img}_shard*.\"\"\"\n",
    "    SHARDS_ROOT = \"D:/User Data/Downloads/rsna-intracranial-aneurysm-detection/cache\"\n",
    "    pattern = os.path.join(SHARDS_ROOT, \"*\", f\"cache_u8_{CFG.img_size}_shard*\")\n",
    "    shard_roots = sorted([p for p in glob.glob(pattern) if os.path.isdir(p)])\n",
    "    if is_main_process():\n",
    "        print(\"Found shard roots:\", len(shard_roots))\n",
    "        for p in shard_roots[:8]:\n",
    "            print(\"  \", p)\n",
    "    return shard_roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6156b07a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T21:36:29.416262Z",
     "iopub.status.busy": "2025-09-25T21:36:29.415897Z",
     "iopub.status.idle": "2025-09-25T21:36:29.468720Z",
     "shell.execute_reply": "2025-09-25T21:36:29.467906Z"
    },
    "papermill": {
     "duration": 0.061487,
     "end_time": "2025-09-25T21:36:29.470325",
     "exception": false,
     "start_time": "2025-09-25T21:36:29.408838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cached Dataset \n",
    "\n",
    "STRICT_CACHE_ONLY = True   # set False to allow on-the-fly fallback\n",
    "\n",
    "def _safe_crop_2d(img: np.ndarray, cx: int, cy: int, size: int) -> np.ndarray:\n",
    "    \"\"\"Center crop with clamping; returns (size,size).\"\"\"\n",
    "    H, W = img.shape\n",
    "    half = size // 2\n",
    "    x0 = max(0, cx - half); x1 = min(W, cx + half)\n",
    "    y0 = max(0, cy - half); y1 = min(H, cy + half)\n",
    "    crop = img[y0:y1, x0:x1]\n",
    "    # pad if we hit borders\n",
    "    if crop.shape[0] != size or crop.shape[1] != size:\n",
    "        pad_y = size - crop.shape[0]\n",
    "        pad_x = size - crop.shape[1]\n",
    "        crop = np.pad(crop,\n",
    "                      ((0, max(0,pad_y)), (0, max(0,pad_x))),\n",
    "                      mode='edge')\n",
    "        crop = crop[:size, :size]\n",
    "    return crop\n",
    "\n",
    "def _resize_2d(img: np.ndarray, out_hw: Tuple[int,int]) -> np.ndarray:\n",
    "    return cv2.resize(img, (out_hw[1], out_hw[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def _map_localizer_to_cached_depth(\n",
    "    loc_z: Optional[float],\n",
    "    loc_f: Optional[int],\n",
    "    cached_depth: int,\n",
    "    orig_depth: Optional[int] = None\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Map a localizer z/f to the 0..cached_depth-1 index space.\n",
    "    - If we know orig_depth, linearly map: round( f / (orig_depth-1) * (cached_depth-1) ).\n",
    "    - Else if we have z as a [0..orig_depth) style value, same idea.\n",
    "    - Else fallback to middle slice.\n",
    "    \"\"\"\n",
    "    if orig_depth and loc_f is not None:\n",
    "        return int(np.clip(round(loc_f / max(1, (orig_depth-1)) * (cached_depth-1)), 0, cached_depth-1))\n",
    "    if orig_depth and loc_z is not None:\n",
    "        return int(np.clip(round(loc_z  / max(1, (orig_depth-1)) * (cached_depth-1)), 0, cached_depth-1))\n",
    "    # fallback middle slice\n",
    "    return cached_depth // 2\n",
    "\n",
    "import os, pydicom, numpy as np\n",
    "from functools import lru_cache\n",
    "\n",
    "def _rank_to_cached_idx(rank: int, orig_depth: int, cached_depth: int) -> int:\n",
    "    if orig_depth <= 1: \n",
    "        return cached_depth // 2\n",
    "    r = np.clip(rank, 0, orig_depth-1)\n",
    "    return int(round(r / (orig_depth - 1) * (cached_depth - 1)))\n",
    "\n",
    "@lru_cache(maxsize=512)\n",
    "def _build_sop_rank_map(series_dir: str) -> tuple[dict, int]:\n",
    "    \"\"\"\n",
    "    Returns (sop_to_rank, orig_depth) for a series, computed by sorting slices by z.\n",
    "    No pixel reads; fast.\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    try:\n",
    "        for name in os.listdir(series_dir):\n",
    "            if not name.lower().endswith(\".dcm\"):\n",
    "                continue\n",
    "            path = os.path.join(series_dir, name)\n",
    "            ds = pydicom.dcmread(path, stop_before_pixels=True, force=True)\n",
    "            sop = str(getattr(ds, \"SOPInstanceUID\", os.path.splitext(name)[0]))\n",
    "            ipp = getattr(ds, \"ImagePositionPatient\", None)\n",
    "            z = float(ipp[2]) if ipp is not None and len(ipp) == 3 else float(getattr(ds, \"SliceLocation\", 0.0))\n",
    "            items.append((sop, z))\n",
    "    except Exception:\n",
    "        pass\n",
    "    if not items:\n",
    "        return ({}, 0)\n",
    "    # sort by z, assign ranks 0..N-1\n",
    "    items.sort(key=lambda t: t[1])\n",
    "    sop_to_rank = {sop: i for i, (sop, _) in enumerate(items)}\n",
    "    return sop_to_rank, len(items)\n",
    "\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "def _sid_seed(sid: str, salt: str = \"locrand\") -> int:\n",
    "    h = hashlib.sha1((salt + sid).encode()).hexdigest()[:8]\n",
    "    return int(h, 16)\n",
    "\n",
    "def _random_local_points(H: int, W: int, K: int, rng: np.random.Generator) -> list[tuple[int,int]]:\n",
    "    if K <= 0: return []\n",
    "    xs = rng.integers(low=W//8, high=W - W//8, size=K)\n",
    "    ys = rng.integers(low=H//8, high=H - H//8, size=K)\n",
    "    return list(zip(xs.tolist(), ys.tolist()))\n",
    "\n",
    "class RSNADataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        series_root: str,\n",
    "        preproc,  # DICOMPreprocessorKaggle\n",
    "        find_cached_path_fn,\n",
    "        localizers_csv_path: Optional[str] = None,\n",
    "        max_localizer_crops: int = 3,\n",
    "        local_crop_size: int = 128,\n",
    "        sid_to_orig_depth: Optional[Dict[str, int]] = None,  # if you have it\n",
    "    ):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.series_root = series_root\n",
    "        self.preproc = preproc\n",
    "        self.find_cached_path = find_cached_path_fn\n",
    "\n",
    "        # Localizers\n",
    "        localizers_csv_path = CFG.localizers_csv_path\n",
    "        self.localizers_map: Dict[str, List[dict]] = load_localizers_csv(\n",
    "            localizers_csv_path, max_points_per_series=max_localizer_crops\n",
    "        ) if localizers_csv_path else {}\n",
    "        self.max_localizer_crops = max_localizer_crops\n",
    "        self.local_crop_size = int(local_crop_size)\n",
    "        self.sid_to_orig_depth = sid_to_orig_depth or {}\n",
    "        self._epoch = 0\n",
    "        self._rng = np.random.default_rng(CFG.seed)\n",
    "\n",
    "    def set_epoch(self, e: int):\n",
    "        self._epoch = int(e)\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        sid = str(row[\"SeriesInstanceUID\"])\n",
    "        cp = self.find_cached_path(sid, CFG.img_size)\n",
    "\n",
    "        # tiny helper: 2D resize to (H,W) \n",
    "        import cv2\n",
    "        def resize2d(arr2d, out_hw):\n",
    "            h, w = int(out_hw[0]), int(out_hw[1])\n",
    "            if arr2d.shape != (h, w):\n",
    "                return cv2.resize(arr2d, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "            return arr2d\n",
    "\n",
    "        # load cached (or preprocess) \n",
    "        if cp is not None:\n",
    "            vol_u8 = np.load(cp, mmap_mode=\"r\")  # (C,H,W) usually C==32\n",
    "        else:\n",
    "            if STRICT_CACHE_ONLY:\n",
    "                raise FileNotFoundError(f\"Not found in cache: {sid}_{CFG.img_size}.npy\")\n",
    "            series_path = os.path.join(self.series_root, sid)\n",
    "            vol = self.preproc.process_series(series_path)  # (32,H,W) float32 0..255\n",
    "            vol_u8 = vol if vol.dtype == np.uint8 else np.clip(vol, 0, 255).astype(np.uint8)\n",
    "\n",
    "        # sanity / resize base stack to (H,W) \n",
    "        if vol_u8.ndim != 3:\n",
    "            raise ValueError(f\"Expected (C,H,W), got {tuple(vol_u8.shape)}\")\n",
    "        base_C = vol_u8.shape[0]\n",
    "        if base_C < 32:\n",
    "            raise ValueError(f\"Expected at least 32 slices, got {base_C}\")\n",
    "\n",
    "        H, W = vol_u8.shape[1], vol_u8.shape[2]\n",
    "        if (H != CFG.img_size) or (W != CFG.img_size):\n",
    "            vol_u8 = np.stack(\n",
    "                [cv2.resize(vol_u8[c], (CFG.img_size, CFG.img_size), interpolation=cv2.INTER_LINEAR)\n",
    "                for c in range(vol_u8.shape[0])],\n",
    "                axis=0\n",
    "            )\n",
    "            H, W = CFG.img_size, CFG.img_size  # recompute\n",
    "\n",
    "        #  optional vesselness sidecar (added b4 localizers) \n",
    "        # sidecar filename: \"<sid>_<img>_vessel_u8.npy\"\n",
    "        if cp is not None:\n",
    "            guess1 = cp.replace(f\"_{CFG.img_size}.npy\", f\"_{CFG.img_size}_vessel_u8.npy\")\n",
    "            guess2 = os.path.join(os.path.dirname(cp), f\"{sid}_{CFG.img_size}_vessel_u8.npy\")\n",
    "            sidecar_path = guess1 if os.path.exists(guess1) else (guess2 if os.path.exists(guess2) else None)\n",
    "        else:\n",
    "            sidecar_path = None\n",
    "\n",
    "        if getattr(CFG, \"use_vessel_sidecar\", True) and sidecar_path is not None:\n",
    "            vess = np.load(sidecar_path, mmap_mode=\"r\")  # (H,W) or (32,H,W)\n",
    "            mode = getattr(CFG, \"vessel_sidecar_mode\", \"mip\")  # \"mip\" or \"per_slice\"\n",
    "\n",
    "            if vess.ndim == 2:\n",
    "                vess2d = resize2d(np.asarray(vess), (H, W)).astype(np.uint8)\n",
    "                vol_u8 = np.concatenate([vol_u8, vess2d[np.newaxis, ...]], axis=0)\n",
    "\n",
    "            elif vess.ndim == 3:\n",
    "                if vess.shape[-2:] != (H, W):\n",
    "                    vess = np.stack([resize2d(vess[z], (H, W)) for z in range(vess.shape[0])], axis=0)\n",
    "                if mode == \"per_slice\":\n",
    "                    vol_u8 = np.concatenate([vol_u8, vess.astype(np.uint8)], axis=0)        # +32\n",
    "                else:\n",
    "                    vess2d = np.asarray(vess).max(axis=0).astype(np.uint8)                  # +1\n",
    "                    vol_u8 = np.concatenate([vol_u8, vess2d[np.newaxis, ...]], axis=0)\n",
    "\n",
    "        # localizer-based extra channels (fixed K) \n",
    "        local_chans = []\n",
    "        K = self.max_localizer_crops\n",
    "        force_random = False\n",
    "\n",
    "        pgo = getattr(CFG, \"p_global_localizer_off\", 0.0)\n",
    "        if pgo > 0:\n",
    "            grng = np.random.default_rng(hash(('global_off', sid, self._epoch, CFG.seed)) & 0xffffffff)\n",
    "            if grng.random() < pgo:\n",
    "                force_random = True\n",
    "\n",
    "        if CFG.use_localizers and K > 0:\n",
    "            # Build MIPs from the first 32 slices only (do not include sidecar channels)\n",
    "            vol_for_mip = vol_u8[:32] if vol_u8.shape[0] >= 32 else vol_u8\n",
    "            cached_depth = vol_for_mip.shape[0]\n",
    "\n",
    "            hint_orig_depth = self.sid_to_orig_depth.get(sid, None)\n",
    "            series_dir = os.path.join(self.series_root, sid)\n",
    "            if os.path.isdir(series_dir):\n",
    "                sop_to_rank, hdr_orig_depth = _build_sop_rank_map(series_dir)\n",
    "            else:\n",
    "                sop_to_rank, hdr_orig_depth = ({}, 0)\n",
    "            use_orig_depth = hint_orig_depth or hdr_orig_depth or cached_depth\n",
    "\n",
    "            rng = np.random.default_rng(hash((sid, self._epoch, CFG.seed)) & 0xffffffff)\n",
    "            use_random = force_random or (rng.random() < CFG.p_localizer_dropout)\n",
    "\n",
    "            pts = self.localizers_map.get(sid, [])\n",
    "            use_pts = (len(pts) > 0) and (not use_random)\n",
    "\n",
    "            if use_pts:\n",
    "                for p in pts[:K]:\n",
    "                    sop = p.get('sop')\n",
    "                    if sop and sop in sop_to_rank and use_orig_depth > 0:\n",
    "                        rank = sop_to_rank[sop]\n",
    "                        z_idx = _rank_to_cached_idx(rank, use_orig_depth, cached_depth)\n",
    "                    else:\n",
    "                        z_idx = _map_localizer_to_cached_depth(\n",
    "                            p.get('z'), p.get('f'),\n",
    "                            cached_depth=cached_depth, orig_depth=use_orig_depth\n",
    "                        )\n",
    "                    z0 = max(0, z_idx - 8); z1 = min(cached_depth, z_idx + 9)\n",
    "                    slab = vol_for_mip[z0:z1]\n",
    "                    mip = slab.max(axis=0) if slab.size else np.zeros((H, W), dtype=vol_u8.dtype)\n",
    "\n",
    "                    px, py = p.get('x'), p.get('y')\n",
    "                    if px is None or py is None:\n",
    "                        cx, cy = W // 2, H // 2\n",
    "                    else:\n",
    "                        cx = int(round(np.clip(px, 0, W - 1)))\n",
    "                        cy = int(round(np.clip(py, 0, H - 1)))\n",
    "\n",
    "                    crop = _safe_crop_2d(mip, cx, cy, size=self.local_crop_size)\n",
    "                    crop_full = resize2d(crop, (H, W))\n",
    "                    local_chans.append(crop_full[np.newaxis, ...])\n",
    "\n",
    "            if len(local_chans) < K:\n",
    "                need = K - len(local_chans)\n",
    "                z_rng = np.random.default_rng(hash((sid, 'z', self._epoch, CFG.seed)) & 0xffffffff)\n",
    "                cz = z_rng.integers(low=0, high=max(1, cached_depth), size=need)\n",
    "                for i in range(need):\n",
    "                    z_idx = int(cz[i])\n",
    "                    z0 = max(0, z_idx - 8); z1 = min(cached_depth, z_idx + 9)\n",
    "                    slab = vol_for_mip[z0:z1]\n",
    "                    mip = slab.max(axis=0) if slab.size else np.zeros((H, W), dtype=vol_u8.dtype)\n",
    "\n",
    "                    rrng = np.random.default_rng(hash((sid, 'xy', i, self._epoch, CFG.seed)) & 0xffffffff)\n",
    "                    (cx, cy) = _random_local_points(H, W, 1, rrng)[0]\n",
    "\n",
    "                    crop = _safe_crop_2d(mip, cx, cy, size=self.local_crop_size)\n",
    "                    crop_full = resize2d(crop, (H, W))\n",
    "                    local_chans.append(crop_full[np.newaxis, ...])\n",
    "\n",
    "            if len(local_chans) > K:\n",
    "                local_chans = local_chans[:K]\n",
    "            extra = np.concatenate(local_chans, axis=0) if local_chans else np.zeros((K, H, W), dtype=vol_u8.dtype)\n",
    "            vol_u8 = np.concatenate([vol_u8, extra], axis=0)\n",
    "\n",
    "        #  final channel alignment to CFG.in_chans \n",
    "        C = vol_u8.shape[0]\n",
    "        target_C = int(CFG.in_chans)\n",
    "        if C < target_C:\n",
    "            pad = np.zeros((target_C - C, H, W), dtype=vol_u8.dtype)\n",
    "            vol_u8 = np.concatenate([vol_u8, pad], axis=0)\n",
    "        elif C > target_C:\n",
    "            vol_u8 = vol_u8[:target_C]\n",
    "\n",
    "        # --- to tensor ---\n",
    "        x = torch.from_numpy(np.asarray(vol_u8)).to(torch.float32).div_(255.0)  # (C,H,W) in [0,1]\n",
    "        y = torch.tensor(row[LABEL_COLS].values.astype(np.float32))\n",
    "        return x, y, sid\n",
    "\n",
    "\n",
    "    # def __getitem__(self, idx):\n",
    "    #     row = self.df.iloc[idx]\n",
    "    #     sid = str(row[\"SeriesInstanceUID\"])\n",
    "    #     cp = self.find_cached_path(sid, CFG.img_size)\n",
    "    \n",
    "    #     # --- load cached (or preprocess) ---\n",
    "    #     if cp is not None:\n",
    "    #         vol_u8 = np.load(cp, mmap_mode=\"r\")  # (C,H,W) or (32,H,W)\n",
    "    #     else:\n",
    "    #         if STRICT_CACHE_ONLY:\n",
    "    #             raise FileNotFoundError(f\"Not found in cache: {sid}_{CFG.img_size}.npy\")\n",
    "    #         series_path = os.path.join(self.series_root, sid)\n",
    "    #         vol = self.preproc.process_series(series_path)  # (32,H,W) float32 0..255\n",
    "    #         vol_u8 = vol if vol.dtype == np.uint8 else np.clip(vol, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    #     # --- sanity checks / shapes ---\n",
    "    #     if vol_u8.ndim != 3:\n",
    "    #         raise ValueError(f\"Expected (C,H,W), got {tuple(vol_u8.shape)}\")\n",
    "    #     base_C = vol_u8.shape[0]\n",
    "    #     if base_C < 32:\n",
    "    #         raise ValueError(f\"Expected at least 32 slices, got {base_C}\")\n",
    "    \n",
    "    #     H, W = vol_u8.shape[1], vol_u8.shape[2]\n",
    "    #     if (H != CFG.img_size) or (W != CFG.img_size):\n",
    "    #         import cv2\n",
    "    #         vol_u8 = np.stack(\n",
    "    #             [cv2.resize(vol_u8[c], (CFG.img_size, CFG.img_size), interpolation=cv2.INTER_LINEAR)\n",
    "    #              for c in range(vol_u8.shape[0])],\n",
    "    #             axis=0\n",
    "    #         )\n",
    "    #     # recompute after possible resize\n",
    "    #     H, W = vol_u8.shape[1], vol_u8.shape[2]\n",
    "\n",
    "    #     # ---- localizer-based extra channels (fixed K) ----\n",
    "    #     local_chans = []\n",
    "    #     K = self.max_localizer_crops\n",
    "    #     force_random = False\n",
    "\n",
    "    #     # Global-off: keep K the same, but ignore real points for this sample\n",
    "    #     pgo = getattr(CFG, \"p_global_localizer_off\", 0.0)\n",
    "    #     if pgo > 0:\n",
    "    #         grng = np.random.default_rng(hash(('global_off', sid, self._epoch, CFG.seed)) & 0xffffffff)\n",
    "    #         if grng.random() < pgo:\n",
    "    #             force_random = True\n",
    "\n",
    "    #     if CFG.use_localizers and K > 0:\n",
    "    #         vol_for_mip = vol_u8[:32] if base_C >= 32 else vol_u8\n",
    "    #         cached_depth = vol_for_mip.shape[0]\n",
    "\n",
    "    #         hint_orig_depth = self.sid_to_orig_depth.get(sid, None)\n",
    "    #         series_dir = os.path.join(self.series_root, sid)\n",
    "    #         if os.path.isdir(series_dir):\n",
    "    #             sop_to_rank, hdr_orig_depth = _build_sop_rank_map(series_dir)\n",
    "    #         else:\n",
    "    #             sop_to_rank, hdr_orig_depth = ({}, 0)\n",
    "    #         use_orig_depth = hint_orig_depth or hdr_orig_depth or cached_depth\n",
    "\n",
    "    #         rng = np.random.default_rng(hash((sid, self._epoch, CFG.seed)) & 0xffffffff)\n",
    "    #         # anti-leakage dropout OR forced-random from global-off\n",
    "    #         use_random = force_random or (rng.random() < CFG.p_localizer_dropout)\n",
    "\n",
    "    #         pts = self.localizers_map.get(sid, [])\n",
    "    #         use_pts = (len(pts) > 0) and (not use_random)\n",
    "\n",
    "    #         if use_pts:\n",
    "    #             for p in pts[:K]:\n",
    "    #                 sop = p.get('sop')\n",
    "    #                 if sop and sop in sop_to_rank and use_orig_depth > 0:\n",
    "    #                     rank = sop_to_rank[sop]\n",
    "    #                     z_idx = _rank_to_cached_idx(rank, use_orig_depth, cached_depth)\n",
    "    #                 else:\n",
    "    #                     z_idx = _map_localizer_to_cached_depth(\n",
    "    #                         p.get('z'), p.get('f'), cached_depth=cached_depth, orig_depth=use_orig_depth\n",
    "    #                     )\n",
    "    #                 z0 = max(0, z_idx - 8); z1 = min(cached_depth, z_idx + 9)\n",
    "    #                 slab = vol_for_mip[z0:z1]\n",
    "    #                 mip = slab.max(axis=0) if slab.size else np.zeros((H, W), dtype=vol_u8.dtype)\n",
    "\n",
    "    #                 px, py = p.get('x'), p.get('y')\n",
    "    #                 if px is None or py is None:\n",
    "    #                     cx, cy = W // 2, H // 2\n",
    "    #                 else:\n",
    "    #                     cx = int(round(np.clip(px, 0, W - 1)))\n",
    "    #                     cy = int(round(np.clip(py, 0, H - 1)))\n",
    "\n",
    "    #                 crop = _safe_crop_2d(mip, cx, cy, size=self.local_crop_size)\n",
    "    #                 crop_full = _resize_2d(crop, (H, W))\n",
    "    #                 local_chans.append(crop_full[np.newaxis, ...])\n",
    "\n",
    "    #         # Fill up to K with deterministic random crops (epoch-varying)\n",
    "    #         if len(local_chans) < K:\n",
    "    #             need = K - len(local_chans)\n",
    "    #             z_rng = np.random.default_rng(hash((sid, 'z', self._epoch, CFG.seed)) & 0xffffffff)\n",
    "    #             cz = z_rng.integers(low=0, high=max(1, cached_depth), size=need)\n",
    "    #             for i in range(need):\n",
    "    #                 z_idx = int(cz[i])\n",
    "    #                 z0 = max(0, z_idx - 8); z1 = min(cached_depth, z_idx + 9)\n",
    "    #                 slab = vol_for_mip[z0:z1]\n",
    "    #                 mip = slab.max(axis=0) if slab.size else np.zeros((H, W), dtype=vol_u8.dtype)\n",
    "\n",
    "    #                 rrng = np.random.default_rng(hash((sid, 'xy', i, self._epoch, CFG.seed)) & 0xffffffff)\n",
    "    #                 (cx, cy) = _random_local_points(H, W, 1, rrng)[0]\n",
    "\n",
    "    #                 crop = _safe_crop_2d(mip, cx, cy, size=self.local_crop_size)\n",
    "    #                 crop_full = _resize_2d(crop, (H, W))\n",
    "    #                 local_chans.append(crop_full[np.newaxis, ...])\n",
    "\n",
    "    #         # Trim (paranoia) and concat\n",
    "    #         if len(local_chans) > K:\n",
    "    #             local_chans = local_chans[:K]\n",
    "    #         extra = np.concatenate(local_chans, axis=0) if local_chans else np.zeros((K, H, W), dtype=vol_u8.dtype)\n",
    "    #         vol_u8 = np.concatenate([vol_u8, extra], axis=0)\n",
    "\n",
    "\n",
    "    #     # --- to tensor ---\n",
    "    #     x = torch.from_numpy(np.asarray(vol_u8)).to(torch.float32).div_(255.0)  # (C,H,W)\n",
    "    #     y = torch.tensor(row[LABEL_COLS].values.astype(np.float32))\n",
    "    #     return x, y, sid\n",
    "\n",
    "\n",
    "#  smarter stratification helpers \n",
    "\n",
    "def _age_to_bin(s: pd.Series) -> pd.Series:\n",
    "    # PatientAge can be like \"067Y\" or numeric; coerce to number of years\n",
    "    raw = pd.to_numeric(s.astype(str).str.extract(r'(\\d+)')[0], errors='coerce')\n",
    "    # decade-ish bins; fill missing as -1\n",
    "    bins = pd.cut(raw, bins=[0,30,40,50,60,70,80,200], labels=False, include_lowest=True)\n",
    "    return bins.fillna(-1).astype(int)\n",
    "\n",
    "def _slice_bin_for_series(series_root: str, sid: str) -> int:\n",
    "    \"\"\"Super-cheap proxy for series 'size': count DICOM files in folder.\"\"\"\n",
    "    p = os.path.join(series_root, str(sid))\n",
    "    n = 0\n",
    "    try:\n",
    "        with os.scandir(p) as it:\n",
    "            for e in it:\n",
    "                if e.is_file():\n",
    "                    n += 1\n",
    "                    # (optional) early stop to keep it fast\n",
    "                    if n > 300: \n",
    "                        break\n",
    "    except FileNotFoundError:\n",
    "        n = 0\n",
    "    # bucketize\n",
    "    if n <= 64:   return 0\n",
    "    if n <= 128:  return 1\n",
    "    if n <= 256:  return 2\n",
    "    return 3\n",
    "\n",
    "def _make_strat_key(df: pd.DataFrame) -> pd.Series:\n",
    "    # core target\n",
    "    ap = df[\"Aneurysm Present\"].astype(int)\n",
    "\n",
    "    # simple categorical covariates (normalized)\n",
    "    mod = df.get(\"Modality\", \"UNK\").astype(str).str.upper().fillna(\"UNK\")\n",
    "    sex = df.get(\"PatientSex\", \"UNK\").astype(str).str.upper().fillna(\"UNK\")\n",
    "\n",
    "    # age bins\n",
    "    ageb = _age_to_bin(df.get(\"PatientAge\", pd.Series([-1]*len(df))))\n",
    "\n",
    "    # slice-count bins (very fast directory count)\n",
    "    # note: uses CFG.series_root and SeriesInstanceUID\n",
    "    slb = df[\"SeriesInstanceUID\"].astype(str).apply(lambda sid: _slice_bin_for_series(CFG.series_root, sid))\n",
    "\n",
    "    # compose a single strat label\n",
    "    key = (\n",
    "        ap.astype(str) + \"_\" +\n",
    "        mod + \"_\" +\n",
    "        sex + \"_\" +\n",
    "        ageb.astype(str) + \"_\" +\n",
    "        pd.Series(slb, index=df.index).astype(str)\n",
    "    )\n",
    "    return key\n",
    "\n",
    "def build_folds() -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Load CSV, keep existing series, add fold column with composite stratification.\"\"\"\n",
    "    df = pd.read_csv(CFG.train_csv)\n",
    "\n",
    "    # keep only series that actually exist on disk\n",
    "    exists = df[\"SeriesInstanceUID\"].apply(lambda u: os.path.isdir(os.path.join(CFG.series_root, str(u))))\n",
    "    df = df[exists].reset_index(drop=True)\n",
    "\n",
    "    # composite strat key: target + modality + sex + age bin + slice-count bin\n",
    "    strat_key = _make_strat_key(df)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=CFG.folds, shuffle=True, random_state=CFG.seed)\n",
    "    df[\"fold\"] = -1\n",
    "    for fold_i, (_, val_idx) in enumerate(skf.split(df, strat_key)):\n",
    "        df.loc[val_idx, \"fold\"] = fold_i\n",
    "\n",
    "    fold_idx = 0  # choose default here; you can pass a different one into build_loaders\n",
    "    train_df = df[df[\"fold\"] != fold_idx].reset_index(drop=True)\n",
    "    val_df   = df[df[\"fold\"] == fold_idx].reset_index(drop=True)\n",
    "    return df, train_df, val_df\n",
    "\n",
    "def load_sid_to_orig_depth(\n",
    "    shard_roots: list[str],\n",
    "    img_size: int,\n",
    "    extra_search_roots: list[str] | None = None,\n",
    "    verbose: bool = True,\n",
    ") -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Recursively search under each root for 'manifest_{img_size}.parquet' and build:\n",
    "        { SeriesInstanceUID -> orig_depth }\n",
    "    Works for paths like:\n",
    "      D:/.../cache/SHARD_ID=0/cache_u8_384_shard00/manifest_384.parquet\n",
    "    \"\"\"\n",
    "    # Collect candidate manifest files (recursive, Windows-safe)\n",
    "    roots = (shard_roots or []) + (extra_search_roots or [])\n",
    "    man_paths = set()\n",
    "    for root in roots:\n",
    "        if not root or not os.path.isdir(root):\n",
    "            continue\n",
    "        # same-dir check\n",
    "        p = os.path.join(root, f\"manifest_{img_size}.parquet\")\n",
    "        if os.path.exists(p):\n",
    "            man_paths.add(os.path.normpath(p))\n",
    "        # recursive search (any depth)\n",
    "        pattern = os.path.join(root, \"**\", f\"manifest_{img_size}.parquet\")\n",
    "        for mp in glob.glob(pattern, recursive=True):\n",
    "            man_paths.add(os.path.normpath(mp))\n",
    "\n",
    "    if not man_paths:\n",
    "        if verbose:\n",
    "            print(\"[manifest] No manifest files found under provided roots.\")\n",
    "        return {}\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[manifest] Found {len(man_paths)} manifest(s).\")\n",
    "\n",
    "    sid_to_depth: dict[str, int] = {}\n",
    "    for mp in sorted(man_paths):\n",
    "        try:\n",
    "            m = pd.read_parquet(mp)                         \n",
    "        except Exception:\n",
    "            m = pd.read_parquet(mp, engine=\"fastparquet\") # fallback\n",
    "        if not {\"SeriesInstanceUID\", \"orig_depth\"}.issubset(m.columns):\n",
    "            continue\n",
    "        sub = m[[\"SeriesInstanceUID\", \"orig_depth\"]].dropna(subset=[\"orig_depth\"])\n",
    "        for sid, od in zip(sub[\"SeriesInstanceUID\"].astype(str), sub[\"orig_depth\"].astype(int)):\n",
    "            # \"latest wins\" if duplicates across shards\n",
    "            sid_to_depth[sid] = int(od)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[manifest] Loaded orig_depth for {len(sid_to_depth)} series.\")\n",
    "    return sid_to_depth\n",
    "\n",
    "\n",
    "def build_loaders(fold_idx: int = 0):\n",
    "    \"\"\"\n",
    "    Build train/val DataLoaders with DistributedSampler if WORLD_SIZE>1.\n",
    "    Uses the same composite stratification as build_folds().\n",
    "    \"\"\"\n",
    "    # discover cache + resolver\n",
    "    shard_roots = discover_shard_roots()\n",
    "\n",
    "    # build an O(1) index: (uid, size) -> path  [RECURSIVE!]\n",
    "    uid_to_path = {}\n",
    "    pattern = f\"*_{CFG.img_size}.npy\"\n",
    "    for root in shard_roots:\n",
    "        for p in glob.glob(os.path.join(root, \"**\", pattern), recursive=True):\n",
    "            fname = os.path.basename(p)            # e.g. \"1.2.840..._384.npy\"\n",
    "            uid, size_part = fname.rsplit(\"_\", 1)  # [\"1.2.840...\", \"384.npy\"]\n",
    "            size = int(size_part.split(\".\")[0])    # 384\n",
    "            uid_to_path[(uid, size)] = p\n",
    "\n",
    "    def find_cached_path(uid: str, img_size: int) -> str | None:\n",
    "        return uid_to_path.get((uid, img_size))\n",
    "    \n",
    "    find_cached_path_fn = find_cached_path\n",
    "    # build SeriesInstanceUID -> orig_depth from per-shard manifests\n",
    "    sid_to_orig_depth = load_sid_to_orig_depth(shard_roots, CFG.img_size)\n",
    "    \n",
    "    # distributed env\n",
    "    local_rank, rank, world_size, is_distributed = setup_distributed()\n",
    "    seed_everything(CFG.seed)\n",
    "\n",
    "    # folds (recompute the same split deterministically)\n",
    "    df = pd.read_csv(CFG.train_csv)\n",
    "    exists = df[\"SeriesInstanceUID\"].apply(lambda u: os.path.isdir(os.path.join(CFG.series_root, str(u))))\n",
    "    df = df[exists].reset_index(drop=True)\n",
    "\n",
    "    strat_key = _make_strat_key(df)\n",
    "    skf = StratifiedKFold(n_splits=CFG.folds, shuffle=True, random_state=CFG.seed)\n",
    "    df[\"fold\"] = -1\n",
    "    for fi, (_, val_idx) in enumerate(skf.split(df, strat_key)):\n",
    "        df.loc[val_idx, \"fold\"] = fi\n",
    "\n",
    "    train_df = df[df[\"fold\"] != fold_idx].reset_index(drop=True)\n",
    "    val_df   = df[df[\"fold\"] == fold_idx].reset_index(drop=True)\n",
    "\n",
    "    # optional: quick cache check (main process only)\n",
    "    if is_main_process() and len(shard_roots) > 0 and len(df) > 0:\n",
    "        sample_sid = str(df.iloc[0][\"SeriesInstanceUID\"])\n",
    "        print(\"Sample cached path:\", find_cached_path_fn(sample_sid, CFG.img_size))\n",
    "\n",
    "    # datasets\n",
    "    preproc = DICOMPreprocessorKaggle(target_shape=(CFG.base_slices, CFG.img_size, CFG.img_size))\n",
    "    \n",
    "    train_ds = RSNADataset(\n",
    "        train_df, CFG.series_root, preproc, find_cached_path_fn, \n",
    "        localizers_csv_path=getattr(CFG, \"localizers_csv_path\", None),\n",
    "        max_localizer_crops=getattr(CFG, \"max_localizer_crops\", 3),\n",
    "        local_crop_size=getattr(CFG, \"local_crop_size\", 128),\n",
    "        sid_to_orig_depth=sid_to_orig_depth,)\n",
    "    \n",
    "    val_ds = RSNADataset(\n",
    "        val_df,   CFG.series_root, preproc, find_cached_path_fn,\n",
    "        localizers_csv_path=getattr(CFG, \"localizers_csv_path\", None),\n",
    "        max_localizer_crops=getattr(CFG, \"max_localizer_crops\", 3),\n",
    "        local_crop_size=getattr(CFG, \"local_crop_size\", 128),\n",
    "        sid_to_orig_depth=sid_to_orig_depth,\n",
    "    )\n",
    "\n",
    "    # samplers\n",
    "    if world_size > 1:\n",
    "        train_sampler = DistributedSampler(train_ds, num_replicas=world_size, rank=rank, shuffle=True, drop_last=True)\n",
    "        val_sampler   = DistributedSampler(val_ds,   num_replicas=world_size, rank=rank, shuffle=False, drop_last=False)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "        val_sampler   = None\n",
    "\n",
    "    # loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG.batch_size,             # per-GPU\n",
    "        sampler=train_sampler,\n",
    "        shuffle=(train_sampler is None),\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        persistent_workers=(CFG.num_workers > 0),\n",
    "        prefetch_factor=2 if CFG.num_workers > 0 else None,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=max(1, CFG.batch_size // 2),\n",
    "        sampler=val_sampler,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=(CFG.num_workers > 0),\n",
    "        prefetch_factor=2 if CFG.num_workers > 0 else None,\n",
    "    )\n",
    "\n",
    "    if is_main_process():\n",
    "        print(f\"World size: {world_size}  |  Rank: {rank}  |  Local rank: {local_rank}\")\n",
    "        print(f\"Train: {len(train_ds)} | Val: {len(val_ds)}\")\n",
    "\n",
    "    return train_loader, val_loader, fold_idx, world_size, rank, local_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87799e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T21:36:29.483444Z",
     "iopub.status.busy": "2025-09-25T21:36:29.483127Z",
     "iopub.status.idle": "2025-09-25T21:36:29.526552Z",
     "shell.execute_reply": "2025-09-25T21:36:29.525769Z"
    },
    "papermill": {
     "duration": 0.051919,
     "end_time": "2025-09-25T21:36:29.527935",
     "exception": false,
     "start_time": "2025-09-25T21:36:29.476016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BCEWithLogitsSmooth(nn.Module):\n",
    "    def __init__(self, smoothing=0.0, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.pos_weight = pos_weight\n",
    "    def forward(self, logits, targets):\n",
    "        if self.smoothing > 0.0:\n",
    "            targets = targets * (1 - self.smoothing) + 0.5 * self.smoothing\n",
    "        return nn.functional.binary_cross_entropy_with_logits(logits, targets, pos_weight=self.pos_weight)\n",
    "\n",
    "class FocalWithLogits(nn.Module):\n",
    "    def __init__(self, gamma=1.5, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma; self.pos_weight = pos_weight\n",
    "    def forward(self, logits, targets):\n",
    "        bce = nn.functional.binary_cross_entropy_with_logits(logits, targets, pos_weight=self.pos_weight, reduction=\"none\")\n",
    "        p = torch.sigmoid(logits); pt = p*targets + (1-p)*(1-targets)\n",
    "        return ((1-pt)**self.gamma * bce).mean()\n",
    "\n",
    "def cosine_sched(step, total_steps, base_lr, min_lr, warmup_steps):\n",
    "    if step < warmup_steps:\n",
    "        return base_lr * (step / max(1, warmup_steps))\n",
    "    t = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "    return min_lr + 0.5*(base_lr - min_lr)*(1 + math.cos(math.pi*t))\n",
    "\n",
    "def make_model():\n",
    "    model = timm.create_model(\n",
    "        CFG.model_name,\n",
    "        in_chans=CFG.in_chans,\n",
    "        num_classes=CFG.num_classes,\n",
    "        img_size=CFG.img_size,\n",
    "        pretrained=True\n",
    "    )\n",
    "    if USE_CHANNELS_LAST:\n",
    "        model = model.to(memory_format=torch.channels_last)\n",
    "    # optional compile for a few extra %\n",
    "    if USE_TORCH_COMPILE:\n",
    "        try:\n",
    "            model = torch.compile(model, mode=\"reduce-overhead\", fullgraph=False)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return model\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, train_loader, val_loader, fold: int):\n",
    "        # DDP env\n",
    "        self.local_rank, self.rank, self.world, self.is_distributed = setup_distributed()\n",
    "        dtype = torch.float16 if AMP_DTYPE == \"bf16\" else torch.bfloat16 if AMP_DTYPE == \"bf16\" else None\n",
    "\n",
    "        # device & model\n",
    "        self.device = torch.device(\"cuda\", self.local_rank) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        torch.cuda.set_device(self.local_rank if torch.cuda.is_available() else 0)\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "        self.model = make_model().to(self.device)\n",
    "\n",
    "        if self.is_distributed:\n",
    "            # important: broadcast buffers True, find_unused False for speed\n",
    "            self.model = DDP(\n",
    "                self.model,\n",
    "                device_ids=[self.local_rank],\n",
    "                output_device=self.local_rank,\n",
    "                broadcast_buffers=True,\n",
    "                find_unused_parameters=False,\n",
    "            )\n",
    "\n",
    "        # loss / opt / scaler\n",
    "        pos_weight = torch.tensor([CFG.pos_weight]*CFG.num_classes, device=self.device)\n",
    "        self.criterion = (FocalWithLogits(CFG.focal_gamma, pos_weight)\n",
    "                          if CFG.focal_loss else BCEWithLogitsSmooth(CFG.label_smoothing, pos_weight))\n",
    "\n",
    "        base_lr = CFG.lr  # no scaling; keeps LR stable moving from 1->2 GPUs\n",
    "        # base_lr = scale_lr_for_world_size(CFG.lr)  # linear scale with world size\n",
    "        self.optimizer = optim.AdamW(self.model.parameters(), lr=base_lr, weight_decay=CFG.weight_decay)\n",
    "        self.global_step = 0\n",
    "        self.ema_decay = 0.9998\n",
    "        base_model = self.model.module if isinstance(self.model, DDP) else self.model\n",
    "        self.ema = copy.deepcopy(base_model).eval()\n",
    "        # ensure EMA is on the same device & memory format\n",
    "        self.ema.to(self.device)\n",
    "        if USE_CHANNELS_LAST:\n",
    "            self.ema.to(memory_format=torch.channels_last)\n",
    "        for p in self.ema.parameters():\n",
    "            p.requires_grad_(False)\n",
    "            \n",
    "        self.base_lr = self.optimizer.param_groups[0][\"lr\"]\n",
    "        self.scaler = GradScaler(enabled=CFG.use_amp and AMP_DTYPE == \"bf16\")  # GradScaler is for fp16 only\n",
    "\n",
    "        self.train_loader, self.val_loader = train_loader, val_loader\n",
    "        self.fold = fold\n",
    "        self.fold_dir = os.path.join(CFG.out_dir, f\"{CFG.save_name}_seed{CFG.seed}_fold{self.fold}\")\n",
    "        os.makedirs(self.fold_dir, exist_ok=True)\n",
    "        self.total_steps = CFG.epochs * len(train_loader)\n",
    "        self.warmup_steps = int(CFG.warmup_epochs * len(train_loader))\n",
    "        os.makedirs(CFG.out_dir, exist_ok=True)\n",
    "        self.best_auc = -1.0\n",
    "\n",
    "        # remember autocast dtype\n",
    "        self.autocast_dtype = torch.float16 if AMP_DTYPE == \"bf16\" else (torch.bfloat16 if AMP_DTYPE == \"bf16\" else None)\n",
    "\n",
    "    def _cast_input(self, x):\n",
    "        # Keep channels_last for better memory access on T4\n",
    "        if USE_CHANNELS_LAST and x.ndim == 4:\n",
    "            x = x.contiguous(memory_format=torch.channels_last)\n",
    "        return x\n",
    "    \n",
    "    def _update_ema(self, step: int):\n",
    "        \"\"\"EMA update: params with decay; buffers (BN stats) copied 1:1 each step.\n",
    "           On very first step, copy whole state 1:1 (warm start).\"\"\"\n",
    "        src = self.model.module if isinstance(self.model, DDP) else self.model\n",
    "    \n",
    "        # Warm-start EMA at first step to avoid bias\n",
    "        if step == 0:\n",
    "            self.ema.load_state_dict(src.state_dict(), strict=True)\n",
    "            return\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            # 1) EMA for parameters\n",
    "            for pe, pm in zip(self.ema.parameters(), src.parameters()):\n",
    "                pe.mul_(self.ema_decay).add_(pm.detach(), alpha=1.0 - self.ema_decay)\n",
    "            # 2) Direct copy for buffers (BN running stats, etc.)\n",
    "            for be, bm in zip(self.ema.buffers(), src.buffers()):\n",
    "                be.copy_(bm.detach())\n",
    "    \n",
    "    def one_epoch(self, epoch):\n",
    "        if self.is_distributed and hasattr(self.train_loader, \"sampler\") and hasattr(self.train_loader.sampler, \"set_epoch\"):\n",
    "            self.train_loader.sampler.set_epoch(epoch)\n",
    "         # NEW: always update dataset epoch (train & val)\n",
    "        if hasattr(self.train_loader, \"dataset\") and hasattr(self.train_loader.dataset, \"set_epoch\"):\n",
    "            self.train_loader.dataset.set_epoch(epoch)\n",
    "        if hasattr(self.val_loader, \"dataset\") and hasattr(self.val_loader.dataset, \"set_epoch\"):\n",
    "            self.val_loader.dataset.set_epoch(0)  # keep val deterministic\n",
    "    \n",
    "        self.model.train()\n",
    "        running = 0.0\n",
    "        start_step = epoch * len(self.train_loader)\n",
    "        self.optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        iterator = self.train_loader\n",
    "        if is_main_process():\n",
    "            iterator = tqdm(self.train_loader, total=len(self.train_loader), desc=f\"Epoch {epoch+1}\", leave=False)\n",
    "\n",
    "        t0 = time()\n",
    "        for it, (x,y, _) in enumerate(iterator):\n",
    "            x = self._cast_input(x.to(self.device, non_blocking=True))\n",
    "            y = y.to(self.device, non_blocking=True)\n",
    "\n",
    "            lr = cosine_sched(start_step+it, self.total_steps, self.base_lr, CFG.min_lr, self.warmup_steps)\n",
    "            for pg in self.optimizer.param_groups: pg[\"lr\"] = lr\n",
    "\n",
    "            # forward \n",
    "            if CFG.use_amp and self.autocast_dtype is not None:\n",
    "                with autocast(dtype=self.autocast_dtype):\n",
    "                    logits = self.model(x)\n",
    "                    loss = self.criterion(logits, y)\n",
    "            else:\n",
    "                logits = self.model(x)\n",
    "                loss = self.criterion(logits, y)\n",
    "\n",
    "            # backward + step + EMA \n",
    "            if CFG.use_amp and AMP_DTYPE == \"bf16\":\n",
    "                self.scaler.scale(loss).backward()\n",
    "                if CFG.clip_grad_norm:\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    nn.utils.clip_grad_norm_(self.model.parameters(), CFG.clip_grad_norm)\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "\n",
    "                # EMA update with step \n",
    "                self._update_ema(self.global_step)\n",
    "                self.global_step += 1\n",
    "\n",
    "            elif CFG.use_amp and AMP_DTYPE == \"bf16\":\n",
    "                loss.backward()\n",
    "                if CFG.clip_grad_norm:\n",
    "                    nn.utils.clip_grad_norm_(self.model.parameters(), CFG.clip_grad_norm)\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # EMA update with step \n",
    "                self._update_ema(self.global_step)\n",
    "                self.global_step += 1\n",
    "\n",
    "            else:  # fp32\n",
    "                loss.backward()\n",
    "                if CFG.clip_grad_norm:\n",
    "                    nn.utils.clip_grad_norm_(self.model.parameters(), CFG.clip_grad_norm)\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # EMA update with step \n",
    "                self._update_ema(self.global_step)\n",
    "                self.global_step += 1\n",
    "\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            running += loss.item()\n",
    "\n",
    "            if is_main_process() and (it+1) % 20 == 0:\n",
    "                dt = time() - t0\n",
    "                ips = (it+1) * CFG.batch_size / max(dt, 1e-6)\n",
    "                iterator.set_postfix(lr=f\"{lr:.2e}\", loss=f\"{loss.item():.4f}\", ips=f\"{ips:.1f} it/s\")\n",
    "\n",
    "        avg_loss = torch.tensor([running / max(1, len(self.train_loader))], device=self.device)\n",
    "        if self.is_distributed:\n",
    "            dist.all_reduce(avg_loss, op=dist.ReduceOp.AVG)\n",
    "        return avg_loss.item()\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def validate(self):\n",
    "        net = self.ema if getattr(self, \"ema\", None) is not None else (\n",
    "            self.model.module if isinstance(self.model, DDP) else self.model\n",
    "        )\n",
    "        net.eval()\n",
    "    \n",
    "        tot = 0.0\n",
    "        probs_all, tgts_all, sids_all = [], [], []\n",
    "    \n",
    "        for batch in self.val_loader:\n",
    "            # unpack (x,y,sid)\n",
    "            x, y, sid = batch\n",
    "            x = self._cast_input(x.to(self.device, non_blocking=True))\n",
    "            y = y.to(self.device, non_blocking=True)\n",
    "    \n",
    "            with torch.cuda.amp.autocast(enabled=False):\n",
    "                logits = net(x)\n",
    "                loss = self.criterion(logits, y)\n",
    "            tot += float(loss.item())\n",
    "    \n",
    "            probs = torch.sigmoid(logits.float())\n",
    "            probs_all.append(probs.cpu().numpy())\n",
    "            tgts_all.append(y.float().cpu().numpy())\n",
    "            sids_all.extend(list(sid))\n",
    "    \n",
    "        # local stacks\n",
    "        y_prob = np.concatenate(probs_all, axis=0)\n",
    "        y_true = np.concatenate(tgts_all, axis=0)\n",
    "        sids   = np.array(sids_all)\n",
    "    \n",
    "        # clean\n",
    "        y_prob = np.clip(y_prob, 1e-6, 1-1e-6)\n",
    "        finite_mask = np.isfinite(y_prob).all(axis=1) & np.isfinite(y_true).all(axis=1)\n",
    "        y_prob, y_true, sids = y_prob[finite_mask], y_true[finite_mask], sids[finite_mask]\n",
    "    \n",
    "        # gather (no padding)\n",
    "        if self.is_distributed:\n",
    "            local = {\"prob\": y_prob, \"true\": y_true, \"sid\": sids}\n",
    "            gathered = [None] * self.world\n",
    "            dist.all_gather_object(gathered, local)\n",
    "            y_prob = np.concatenate([g[\"prob\"] for g in gathered if g is not None], axis=0)\n",
    "            y_true = np.concatenate([g[\"true\"] for g in gathered if g is not None], axis=0)\n",
    "            sids   = np.concatenate([g[\"sid\"]  for g in gathered if g is not None], axis=0)\n",
    "    \n",
    "        # metrics\n",
    "        aucs = {}\n",
    "        for j, name in enumerate(LABEL_COLS):\n",
    "            yi, pi = y_true[:, j], y_prob[:, j]\n",
    "            m = np.isfinite(yi) & np.isfinite(pi)\n",
    "            yi, pi = yi[m], pi[m]\n",
    "            aucs[name] = roc_auc_score(yi, pi) if np.unique(yi).size >= 2 else np.nan\n",
    "    \n",
    "        wauc = comp_weighted_auc(aucs)\n",
    "        va_loss = tot / max(1, len(self.val_loader))\n",
    "    \n",
    "        # SAVE fold-level OOF chunk (VAL predictions for this fold) on main process\n",
    "        if is_main_process():\n",
    "            df_pred = pd.DataFrame({\"SeriesInstanceUID\": sids})\n",
    "            for j, name in enumerate(LABEL_COLS):\n",
    "                df_pred[name] = y_prob[:, j]\n",
    "            # Optional: include targets for analysis\n",
    "            for j, name in enumerate(LABEL_COLS):\n",
    "                df_pred[f\"{name}_target\"] = y_true[:, j]\n",
    "            oof_path = os.path.join(self.fold_dir, f\"oof_fold{self.fold}_seed{CFG.seed}.csv\")\n",
    "            df_pred.to_csv(oof_path, index=False)\n",
    "    \n",
    "        return va_loss, wauc, aucs, y_prob  # (kept same return shape)\n",
    "\n",
    "    \n",
    "    def fit(self):\n",
    "        best_state = None\n",
    "        no_improve = 0\n",
    "        patience = 7\n",
    "    \n",
    "        for epoch in range(CFG.epochs):\n",
    "            tr_loss = self.one_epoch(epoch)\n",
    "            va_loss, wauc, aucs, _ = self.validate()\n",
    "            ap = aucs[LABEL_COLS[ANEURYSM_PRESENT_IDX]]\n",
    "    \n",
    "            if is_main_process():\n",
    "                print(f\"[{epoch+1:02d}/{CFG.epochs}] tr={tr_loss:.4f}  va={va_loss:.4f}  wAUC={wauc:.5f}  AneurysmPresent={ap:.5f}\")\n",
    "                \n",
    "            if wauc > self.best_auc:\n",
    "                self.best_auc = wauc\n",
    "                no_improve = 0\n",
    "                # Save EMA as the best snapshot\n",
    "                state = copy.deepcopy(self.ema.state_dict())\n",
    "                best_state = state  # keep a local copy for end-of-training reload\n",
    "                if is_main_process():\n",
    "                    torch.save(\n",
    "                    {\"state_dict\": state, \"cfg\": cfg_to_dict(CFG), \"best_wAUC\": float(wauc),\n",
    "                     \"fold\": int(self.fold), \"is_ema\": True},\n",
    "                    os.path.join(self.fold_dir, \"best_ema.pth\")\n",
    "                    )\n",
    "                    # raw/live weights (optional)\n",
    "                    live = (self.model.module if isinstance(self.model, DDP) else self.model).state_dict()\n",
    "                    torch.save(\n",
    "                        {\"state_dict\": live, \"cfg\": cfg_to_dict(CFG), \"best_wAUC\": float(wauc),\n",
    "                         \"fold\": int(self.fold), \"is_ema\": False},\n",
    "                        os.path.join(self.fold_dir, \"best_raw.pth\")\n",
    "                    )\n",
    "                    # metrics sidecar\n",
    "                    with open(os.path.join(self.fold_dir, \"metrics.json\"), \"w\") as f:\n",
    "                        json.dump({\"best_wAUC\": float(wauc), \"epoch\": int(epoch), \"fold\": int(self.fold)}, f, indent=2)\n",
    "            else:\n",
    "                no_improve += 1\n",
    "    \n",
    "            if no_improve >= patience:\n",
    "                if is_main_process(): \n",
    "                    print(\"Early stopping.\")\n",
    "                break\n",
    "    \n",
    "        # Load EMA-best back into the active model so further eval/infer use it\n",
    "        if best_state is not None:\n",
    "            target = self.model.module if isinstance(self.model, DDP) else self.model\n",
    "            target.load_state_dict(best_state, strict=False)\n",
    "    \n",
    "        if is_main_process():\n",
    "            print(\"Best wAUC:\", self.best_auc)\n",
    "    \n",
    "        return self.best_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419aff44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T21:36:29.552651Z",
     "iopub.status.busy": "2025-09-25T21:36:29.552303Z",
     "iopub.status.idle": "2025-09-25T21:36:29.557073Z",
     "shell.execute_reply": "2025-09-25T21:36:29.556291Z"
    },
    "papermill": {
     "duration": 0.012796,
     "end_time": "2025-09-25T21:36:29.558539",
     "exception": false,
     "start_time": "2025-09-25T21:36:29.545743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Single-GPU local run (Windows/Jupyter safe)\n",
    "# import os, platform, torch\n",
    "\n",
    "# print(\"cuda available:\", torch.cuda.is_available())\n",
    "# if torch.cuda.is_available():\n",
    "#     print(\"device name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# CFG.num_workers = 0\n",
    "# CFG.persistent_workers = False\n",
    "# CFG.pin_memory = torch.cuda.is_available()\n",
    "\n",
    "# # Force non-distributed mode\n",
    "# def _setup_dist_dummy():\n",
    "#     # local_rank, rank, world_size, is_distributed\n",
    "#     return 0, 0, 1, False\n",
    "\n",
    "# def _cleanup_dist_dummy():\n",
    "#     pass\n",
    "\n",
    "# # Override any previous distributed helpers\n",
    "# setup_distributed = _setup_dist_dummy\n",
    "# cleanup_distributed = _cleanup_dist_dummy\n",
    "\n",
    "# # Optional: small perf knobs\n",
    "# torch.set_num_threads(max(1, os.cpu_count() // 2))\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.backends.cudnn.benchmark = True  # speeds up convs with fixed input size\n",
    "\n",
    "# # Train single process \n",
    "# from __main__ import build_loaders, Trainer, CFG, seed_everything  # ensure these are defined above\n",
    "\n",
    "# seed_everything(CFG.seed)\n",
    "# train_loader, val_loader, fold_idx, world, r, local = build_loaders(fold_idx=0)\n",
    "# print(f\"[single] world={world} rank={r} local_rank={local}  |  \"\n",
    "#       f\"Train: {len(train_loader.dataset)}  Val: {len(val_loader.dataset)}\")\n",
    "\n",
    "# trainer = Trainer(train_loader, val_loader, fold=fold_idx)\n",
    "# trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29686601",
   "metadata": {
    "papermill": {
     "duration": 0.005695,
     "end_time": "2025-09-25T21:36:29.570057",
     "exception": false,
     "start_time": "2025-09-25T21:36:29.564362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c7770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T21:36:29.583392Z",
     "iopub.status.busy": "2025-09-25T21:36:29.583064Z",
     "iopub.status.idle": "2025-09-25T21:36:29.590283Z",
     "shell.execute_reply": "2025-09-25T21:36:29.589541Z"
    },
    "papermill": {
     "duration": 0.016397,
     "end_time": "2025-09-25T21:36:29.591997",
     "exception": false,
     "start_time": "2025-09-25T21:36:29.575600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #  Inference + Kaggle Server (OFFLINE, multi-seed, robust paths)\n",
    "# import os, gc, shutil, warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# from pathlib import Path\n",
    "# from typing import Dict, Tuple, List, Optional\n",
    "# import numpy as np\n",
    "# import polars as pl\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.cuda.amp import autocast\n",
    "# import timm\n",
    "\n",
    "# ID_COL = \"SeriesInstanceUID\"\n",
    "# TARGET_COLS = LABEL_COLS\n",
    "# NUM_CLASSES = len(TARGET_COLS)\n",
    "\n",
    "# # no internet pulls during submit\n",
    "# os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
    "# os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "\n",
    "# class InferenceCFG:\n",
    "#     model_name: str = CFG.model_name\n",
    "#     img_size:  int = CFG.img_size\n",
    "#     in_chans:  int = CFG.in_chans\n",
    "#     num_classes: int = NUM_CLASSES\n",
    "#     channels_last: bool = True\n",
    "#     use_amp: bool = True\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     base_ckpt_dir: str = \"/kaggle/input/maxvit-base-tf-384-dataset\"\n",
    "#     save_name: str = CFG.save_name  # e.g. \"maxvitbasemodel\"\n",
    "#     # which folds to use currently have fold0 only\n",
    "#     folds: List[int] = [0]\n",
    "\n",
    "#     # filenames we prefer (searched recursively)\n",
    "#     ckpt_prefer = [\"best_ema.pth\", \"ema.pth\", \"model_ema.pth\", \"best_raw.pth\"]\n",
    "\n",
    "# ICFG = InferenceCFG()\n",
    "\n",
    "# def _make_model_for_infer() -> nn.Module:\n",
    "#     m = timm.create_model(\n",
    "#         ICFG.model_name,\n",
    "#         in_chans=ICFG.in_chans,\n",
    "#         num_classes=ICFG.num_classes,\n",
    "#         img_size=ICFG.img_size,\n",
    "#         pretrained=False,      # never fetch online\n",
    "#     )\n",
    "#     if ICFG.channels_last:\n",
    "#         m = m.to(memory_format=torch.channels_last)\n",
    "#     return m\n",
    "\n",
    "# def _find_seed_dirs(base: Path, save_name: str, folds: List[int]) -> List[Path]:\n",
    "#     \"\"\"\n",
    "#     Find seed directories like:\n",
    "#       base / f\"{save_name}_seed{X}_fold{F}\"\n",
    "#     (supports your current nested layout too)\n",
    "#     \"\"\"\n",
    "#     cand_dirs = []\n",
    "#     for p in base.iterdir():\n",
    "#         if not p.is_dir():\n",
    "#             continue\n",
    "#         name = p.name\n",
    "#         if not name.startswith(f\"{save_name}_seed\"):\n",
    "#             continue\n",
    "#         # keep only ones that end with _foldK we care about\n",
    "#         if any(name.endswith(f\"_fold{f}\") for f in folds):\n",
    "#             cand_dirs.append(p)\n",
    "#     return sorted(cand_dirs)\n",
    "\n",
    "# def _find_ckpt_in_dir(dirpath: Path) -> Optional[Path]:\n",
    "#     \"\"\"\n",
    "#     Robust: try preferred filenames under dirpath (recursively).\n",
    "#     If not found, fall back to any *.pth (if unique).\n",
    "#     Handles your nested pattern: <seed_dir>/<same_name>/*.\n",
    "#     \"\"\"\n",
    "#     # try preferred names anywhere under this dir\n",
    "#     for fname in ICFG.ckpt_prefer:\n",
    "#         hits = list(dirpath.rglob(fname))\n",
    "#         if hits:\n",
    "#             return hits[0]\n",
    "\n",
    "#     # else: any *.pth (unique)\n",
    "#     all_pth = list(dirpath.rglob(\"*.pth\"))\n",
    "#     if len(all_pth) == 1:\n",
    "#         return all_pth[0]\n",
    "#     # if multiple, try pick the one with 'ema' in its name\n",
    "#     ema_pth = [p for p in all_pth if \"ema\" in p.name.lower()]\n",
    "#     if len(ema_pth) == 1:\n",
    "#         return ema_pth[0]\n",
    "#     return None\n",
    "\n",
    "# def _load_model_from_ckpt(ckpt_path: Path) -> nn.Module:\n",
    "#     ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "#     state = ckpt.get(\"state_dict\", ckpt.get(\"model\"))\n",
    "#     if state is None:\n",
    "#         raise KeyError(f\"{ckpt_path} missing 'state_dict'/'model' keys\")\n",
    "#     m = _make_model_for_infer()\n",
    "#     m.load_state_dict(state, strict=True)\n",
    "#     m.to(ICFG.device).eval()\n",
    "#     return m\n",
    "\n",
    "# # cache of loaded models, keyed by (seed_dir_name)\n",
    "# _MODELS: Dict[str, nn.Module] = {}\n",
    "\n",
    "# def _ensure_models_loaded():\n",
    "#     if _MODELS:\n",
    "#         return\n",
    "#     base = Path(ICFG.base_ckpt_dir)\n",
    "#     seed_dirs = _find_seed_dirs(base, ICFG.save_name, ICFG.folds)\n",
    "\n",
    "#     if not seed_dirs:\n",
    "#         raise FileNotFoundError(f\"No seed folders found under {base} for save_name={ICFG.save_name}\")\n",
    "\n",
    "#     loaded = 0\n",
    "#     for sd in seed_dirs:\n",
    "#         ckpt = _find_ckpt_in_dir(sd)\n",
    "#         if ckpt is None:\n",
    "#             # skip politely if a seed dir has only OOF csv but no weights\n",
    "#             continue\n",
    "#         try:\n",
    "#             model = _load_model_from_ckpt(ckpt)\n",
    "#             _MODELS[sd.name] = model\n",
    "#             loaded += 1\n",
    "#         except Exception as e:\n",
    "#             # skip broken checkpoints but continue others\n",
    "#             print(f\"Warning: failed to load {ckpt}: {e}\")\n",
    "\n",
    "#     if loaded == 0:\n",
    "#         raise FileNotFoundError(f\"No usable *.pth checkpoints found under {base} (looked recursively).\")\n",
    "\n",
    "#     # optional warmup\n",
    "#     with torch.no_grad():\n",
    "#         dummy = torch.randn(1, ICFG.in_chans, ICFG.img_size, ICFG.img_size, device=ICFG.device)\n",
    "#         for m in _MODELS.values():\n",
    "#             _ = m(dummy)\n",
    "\n",
    "# # preprocessing \n",
    "# def _process_series(series_path: str, target_shape: Tuple[int,int,int]) -> np.ndarray:\n",
    "#     pre = DICOMPreprocessorKaggle(target_shape=target_shape)\n",
    "#     vol = pre.process_series(series_path)  # (32,H,W), uint8 or float in [0,255]\n",
    "#     return vol\n",
    "\n",
    "# # predict \n",
    "# @torch.no_grad()\n",
    "# def _predict_single(model: nn.Module, vol_u8: np.ndarray) -> np.ndarray:\n",
    "#     x = torch.from_numpy(np.asarray(vol_u8)).to(torch.float32).div_(255.0).unsqueeze(0)\n",
    "#     if ICFG.channels_last:\n",
    "#         x = x.contiguous(memory_format=torch.channels_last)\n",
    "#     x = x.to(ICFG.device, non_blocking=True)\n",
    "#     with autocast(enabled=ICFG.use_amp):\n",
    "#         logits = model(x)\n",
    "#     prob = torch.sigmoid(logits.float()).cpu().numpy().squeeze(0)\n",
    "#     return np.clip(prob, 1e-6, 1-1e-6)\n",
    "\n",
    "# def _predict_ensemble(vol_u8: np.ndarray) -> np.ndarray:\n",
    "#     _ensure_models_loaded()\n",
    "#     preds = [_predict_single(m, vol_u8) for m in _MODELS.values()]\n",
    "#     return np.mean(np.stack(preds, 0), 0)\n",
    "\n",
    "# def _predict_inner(series_path: str) -> pl.DataFrame:\n",
    "#     vol = _process_series(series_path, (ICFG.in_chans, ICFG.img_size, ICFG.img_size))\n",
    "#     pred = _predict_ensemble(vol)\n",
    "#     return pl.DataFrame([pred.tolist()], schema=TARGET_COLS)\n",
    "\n",
    "# def predict(series_path: str) -> pl.DataFrame:\n",
    "#     try:\n",
    "#         return _predict_inner(series_path)\n",
    "#     except Exception:\n",
    "#         # conservative fallback\n",
    "#         return pl.DataFrame([[0.1]*NUM_CLASSES], schema=TARGET_COLS)\n",
    "#     finally:\n",
    "#         # required cleanup between served series\n",
    "#         shared_dir = \"/kaggle/shared\"\n",
    "#         shutil.rmtree(shared_dir, ignore_errors=True)\n",
    "#         os.makedirs(shared_dir, exist_ok=True)\n",
    "#         if torch.cuda.is_available():\n",
    "#             torch.cuda.empty_cache()\n",
    "#         gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f8e2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T21:36:29.605107Z",
     "iopub.status.busy": "2025-09-25T21:36:29.604718Z",
     "iopub.status.idle": "2025-09-25T21:36:30.767064Z",
     "shell.execute_reply": "2025-09-25T21:36:30.766241Z"
    },
    "papermill": {
     "duration": 1.170934,
     "end_time": "2025-09-25T21:36:30.768638",
     "exception": false,
     "start_time": "2025-09-25T21:36:29.597704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inference + Kaggle Server (OFFLINE, multi-seed, robust paths) \n",
    "import os, gc, shutil, warnings, glob, ast, hashlib\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import autocast\n",
    "import timm\n",
    "import pydicom\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "\n",
    "# competition constants \n",
    "ID_COL = \"SeriesInstanceUID\"\n",
    "TARGET_COLS = LABEL_COLS\n",
    "NUM_CLASSES = len(TARGET_COLS)\n",
    "\n",
    "# no internet pulls during submit\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "\n",
    "def is_main_process():\n",
    "    # Kaggle server is single-process; define to avoid NameError\n",
    "    return True\n",
    "\n",
    "# load manifests from shard roots \n",
    "def _discover_shard_roots() -> List[str]:\n",
    "    \"\"\"Find all cache shard folders under D:/User Data/Downloads/rsna-intracranial-aneurysm-detection/cache/*/cache_u8_{img}_shard*.\"\"\"\n",
    "    SHARDS_ROOT = \"D:/User Data/Downloads/rsna-intracranial-aneurysm-detection/cache\"\n",
    "    pattern = os.path.join(SHARDS_ROOT, \"*\", f\"cache_u8_{CFG.img_size}_shard*\")\n",
    "    shard_roots = sorted([p for p in glob.glob(pattern) if os.path.isdir(p)])\n",
    "    if is_main_process():\n",
    "        print(\"Found shard roots:\", len(shard_roots))\n",
    "        for p in shard_roots[:8]:\n",
    "            print(\"  \", p)\n",
    "    return shard_roots\n",
    "\n",
    "def _load_sid_to_orig_depth(shard_roots: List[str], img_size: int) -> Dict[str, int]:\n",
    "    sid2: Dict[str, int] = {}\n",
    "    for root in shard_roots:\n",
    "        man = os.path.join(root, f\"manifest_{img_size}.parquet\")\n",
    "        if os.path.exists(man):\n",
    "            try:\n",
    "                m = pd.read_parquet(man)\n",
    "            except Exception:\n",
    "                m = pd.read_parquet(man, engine=\"fastparquet\")\n",
    "            if {\"SeriesInstanceUID\",\"orig_depth\"}.issubset(m.columns):\n",
    "                sub = m[[\"SeriesInstanceUID\",\"orig_depth\"]].dropna()\n",
    "                for sid, od in zip(sub[\"SeriesInstanceUID\"].astype(str), sub[\"orig_depth\"].astype(int)):\n",
    "                    sid2[sid] = int(od)\n",
    "    return sid2\n",
    "\n",
    "# cached path index: (sid, size) -> npy path \n",
    "def _build_uid_to_path(shard_roots: List[str], img_size: int) -> Dict[Tuple[str,int], str]:\n",
    "    idx: Dict[Tuple[str,int], str] = {}\n",
    "    suffix = f\"_{img_size}.npy\"\n",
    "    for root in shard_roots:\n",
    "        with os.scandir(root) as it:\n",
    "            for e in it:\n",
    "                if e.is_file() and e.name.endswith(suffix):\n",
    "                    uid = e.name[:-len(suffix)]\n",
    "                    idx[(uid, img_size)] = e.path\n",
    "    return idx\n",
    "\n",
    "# parse localizers CSV (your schema) \n",
    "def _load_localizers_csv(csv_path: Optional[str], max_points_per_series: int = 3) -> Dict[str, List[dict]]:\n",
    "    \"\"\"\n",
    "    Columns:\n",
    "      - SeriesInstanceUID\n",
    "      - SOPInstanceUID\n",
    "      - coordinates: \"{'x': ..., 'y': ...}\" or '{\"x\":..., \"y\":...}'\n",
    "      - location (optional)\n",
    "    Returns: { sid: [ {'x','y','sop','loc'} ... ] }\n",
    "    \"\"\"\n",
    "    if not csv_path or not os.path.exists(csv_path):\n",
    "        return {}\n",
    "    df = pd.read_csv(csv_path)\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    sid_col   = cols.get('seriesinstanceuid') or 'SeriesInstanceUID'\n",
    "    sop_col   = cols.get('sopinstanceuid')   or 'SOPInstanceUID'\n",
    "    coord_col = cols.get('coordinates')      or 'coordinates'\n",
    "    loc_col   = cols.get('location') if 'location' in cols else None\n",
    "\n",
    "    keep = [c for c in [sid_col, sop_col, coord_col, loc_col] if c and c in df.columns]\n",
    "    df = df[keep].copy()\n",
    "\n",
    "    by_sid: Dict[str, List[dict]] = defaultdict(list)\n",
    "    for _, r in df.iterrows():\n",
    "        sid = str(r[sid_col])\n",
    "        sop = str(r[sop_col]) if sop_col in r and pd.notna(r[sop_col]) else None\n",
    "        x = y = None\n",
    "        if coord_col in r and pd.notna(r[coord_col]):\n",
    "            s = str(r[coord_col]).strip()\n",
    "            try:\n",
    "                xy = ast.literal_eval(s)\n",
    "                x = float(xy.get(\"x\")) if xy.get(\"x\") is not None else None\n",
    "                y = float(xy.get(\"y\")) if xy.get(\"y\") is not None else None\n",
    "            except Exception:\n",
    "                x = y = None\n",
    "        loc = str(r[loc_col]) if loc_col and pd.notna(r[loc_col]) else None\n",
    "        by_sid[sid].append({\"x\": x, \"y\": y, \"sop\": sop, \"loc\": loc})\n",
    "\n",
    "    for sid in list(by_sid.keys()):\n",
    "        by_sid[sid] = by_sid[sid][:max_points_per_series]\n",
    "    return dict(by_sid)\n",
    "\n",
    "# SOP -> rank map (headers only, cached)\n",
    "@lru_cache(maxsize=512)\n",
    "def _build_sop_rank_map(series_dir: str) -> Tuple[Dict[str,int], int]:\n",
    "    items = []\n",
    "    try:\n",
    "        for name in os.listdir(series_dir):\n",
    "            if not name.lower().endswith(\".dcm\"):\n",
    "                continue\n",
    "            path = os.path.join(series_dir, name)\n",
    "            ds = pydicom.dcmread(path, stop_before_pixels=True, force=True)\n",
    "            sop = str(getattr(ds, \"SOPInstanceUID\", os.path.splitext(name)[0]))\n",
    "            ipp = getattr(ds, \"ImagePositionPatient\", None)\n",
    "            z = float(ipp[2]) if ipp is not None and len(ipp) == 3 else float(getattr(ds, \"SliceLocation\", 0.0))\n",
    "            items.append((sop, z))\n",
    "    except Exception:\n",
    "        pass\n",
    "    if not items:\n",
    "        return ({}, 0)\n",
    "    items.sort(key=lambda t: t[1])\n",
    "    return ({sop: i for i, (sop, _) in enumerate(items)}, len(items))\n",
    "\n",
    "def _rank_to_cached_idx(rank: int, orig_depth: int, cached_depth: int) -> int:\n",
    "    if orig_depth <= 1:\n",
    "        return cached_depth // 2\n",
    "    r = np.clip(rank, 0, orig_depth-1)\n",
    "    return int(round(r / (orig_depth - 1) * (cached_depth - 1)))\n",
    "\n",
    "def _map_localizer_to_cached_depth(loc_z, loc_f, cached_depth: int, orig_depth: Optional[int]=None) -> int:\n",
    "    if orig_depth and loc_f is not None:\n",
    "        return int(np.clip(round(loc_f / max(1, (orig_depth-1)) * (cached_depth-1)), 0, cached_depth-1))\n",
    "    if orig_depth and loc_z is not None:\n",
    "        return int(np.clip(round(loc_z  / max(1, (orig_depth-1)) * (cached_depth-1)), 0, cached_depth-1))\n",
    "    return cached_depth // 2\n",
    "\n",
    "class InferenceCFG:\n",
    "    # must match training\n",
    "    model_name: str = CFG.model_name\n",
    "    img_size:  int = CFG.img_size\n",
    "    in_chans:  int = CFG.in_chans\n",
    "    num_classes: int = NUM_CLASSES\n",
    "    channels_last: bool = True\n",
    "    use_amp: bool = True\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # uploaded dataset root \n",
    "    base_ckpt_dir: str = \"D:/User Data/Downloads/rsna-intracranial-aneurysm-detection/outputs/maxvitbasemodel_seed42_fold0\"\n",
    "    save_name: str = CFG.save_name\n",
    "    folds: List[int] = [0]\n",
    "    ckpt_prefer = [\"best_ema.pth\", \"ema.pth\", \"model_ema.pth\", \"best_raw.pth\"]\n",
    "\n",
    "ICFG = InferenceCFG()\n",
    "\n",
    "# (Optional) recompute in_chans defensively to mirror training flags\n",
    "_K = getattr(CFG, \"max_localizer_crops\", 0) if getattr(CFG, \"use_localizers\", False) else 0\n",
    "ICFG.in_chans = CFG.base_slices + getattr(CFG, \"extra_cached_chans\", 0) + _K\n",
    "\n",
    "# Build cache indices and metadata once\n",
    "_SHARD_ROOTS = _discover_shard_roots()\n",
    "_UID2PATH    = _build_uid_to_path(_SHARD_ROOTS, ICFG.img_size)\n",
    "_SID2DEPTH   = _load_sid_to_orig_depth(_SHARD_ROOTS, ICFG.img_size)\n",
    "\n",
    "# Localizers CSV path must match what i used in train\n",
    "_LOCALIZERS = _load_localizers_csv(getattr(CFG, \"localizers_csv_path\", None),\n",
    "                                   max_points_per_series=getattr(CFG, \"max_localizer_crops\", 3))\n",
    "\n",
    "def _load_cached_or_preprocess(series_path: str, sid: str) -> np.ndarray:\n",
    "    cp = _UID2PATH.get((sid, ICFG.img_size))\n",
    "    if cp and os.path.exists(cp):\n",
    "        vol_u8 = np.load(cp, mmap_mode=\"r\")\n",
    "    else:\n",
    "        pre = DICOMPreprocessorKaggle(target_shape=(CFG.base_slices, ICFG.img_size, ICFG.img_size))\n",
    "        vol = pre.process_series(series_path)\n",
    "        vol_u8 = vol if vol.dtype == np.uint8 else np.clip(vol, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # ensure spatial dims\n",
    "    C, H, W = vol_u8.shape\n",
    "    if (H != ICFG.img_size) or (W != ICFG.img_size):\n",
    "        vol_u8 = np.stack(\n",
    "            [cv2.resize(vol_u8[c], (ICFG.img_size, ICFG.img_size), interpolation=cv2.INTER_LINEAR)\n",
    "             for c in range(C)], axis=0)\n",
    "    return vol_u8\n",
    "\n",
    "def _safe_crop_2d(img: np.ndarray, cx: int, cy: int, size: int) -> np.ndarray:\n",
    "    H, W = img.shape\n",
    "    half = size // 2\n",
    "    x0 = max(0, cx - half); x1 = min(W, cx + half)\n",
    "    y0 = max(0, cy - half); y1 = min(H, cy + half)\n",
    "    crop = img[y0:y1, x0:x1]\n",
    "    if crop.shape[0] != size or crop.shape[1] != size:\n",
    "        pad_y = size - crop.shape[0]\n",
    "        pad_x = size - crop.shape[1]\n",
    "        crop = np.pad(crop, ((0, max(0,pad_y)), (0, max(0,pad_x))), mode='edge')\n",
    "        crop = crop[:size, :size]\n",
    "    return crop\n",
    "\n",
    "def _compose_localizer_channels(sid: str, vol_u8: np.ndarray, K: int, crop_size: int=128) -> np.ndarray:\n",
    "    # Inference: do NOT apply train-time dropouts; use points if present, else deterministic random fill.\n",
    "    if K <= 0:\n",
    "        return np.zeros((0, vol_u8.shape[1], vol_u8.shape[2]), dtype=vol_u8.dtype)\n",
    "\n",
    "    pts = _LOCALIZERS.get(sid, [])\n",
    "    H, W = vol_u8.shape[1], vol_u8.shape[2]\n",
    "    base = vol_u8[:CFG.base_slices]\n",
    "    cached_depth = base.shape[0]\n",
    "\n",
    "    # SOP→rank mapping & orig depth\n",
    "    series_dir = os.path.join(CFG.series_root, sid)\n",
    "    sop2rank, hdr_depth = _build_sop_rank_map(series_dir) if os.path.isdir(series_dir) else ({}, 0)\n",
    "    use_depth = _SID2DEPTH.get(sid, None) or hdr_depth or cached_depth\n",
    "\n",
    "    chans = []\n",
    "    for p in pts[:K]:\n",
    "        # choose z\n",
    "        sop = p.get(\"sop\")\n",
    "        if sop and sop in sop2rank and use_depth > 0:\n",
    "            z_idx = _rank_to_cached_idx(sop2rank[sop], use_depth, cached_depth)\n",
    "        else:\n",
    "            z_idx = _map_localizer_to_cached_depth(p.get(\"z\"), p.get(\"f\"), cached_depth, use_depth)\n",
    "        z0 = max(0, z_idx-8); z1 = min(cached_depth, z_idx+9)\n",
    "        slab = base[z0:z1]\n",
    "        if slab.size == 0:\n",
    "            chan = np.zeros((H,W), dtype=vol_u8.dtype)\n",
    "        else:\n",
    "            mip = slab.max(axis=0)\n",
    "            px, py = p.get(\"x\"), p.get(\"y\")\n",
    "            if px is None or py is None:\n",
    "                cx, cy = W//2, H//2\n",
    "            else:\n",
    "                cx = int(round(np.clip(px, 0, W-1)))\n",
    "                cy = int(round(np.clip(py, 0, H-1)))\n",
    "            crop = _safe_crop_2d(mip, cx, cy, size=crop_size)\n",
    "            chan = cv2.resize(crop, (W,H), interpolation=cv2.INTER_LINEAR)\n",
    "        chans.append(chan[np.newaxis, ...])\n",
    "\n",
    "    # deterministic, per-SID filler for any missing channels\n",
    "    def _sid_seed(sid: str, salt: str = \"infer_locrand\") -> int:\n",
    "        h = hashlib.sha1((salt + sid).encode()).hexdigest()[:8]\n",
    "        return int(h, 16)\n",
    "\n",
    "    def _safe_rand_points(H, W, K, rng):\n",
    "        xs = rng.integers(low=W//8, high=W - W//8, size=K)\n",
    "        ys = rng.integers(low=H//8, high=H - H//8, size=K)\n",
    "        return list(zip(xs.tolist(), ys.tolist()))\n",
    "\n",
    "    if len(chans) < K:\n",
    "        need = K - len(chans)\n",
    "        rng = np.random.default_rng(_sid_seed(sid))\n",
    "        cz = rng.integers(low=0, high=max(1, cached_depth), size=need)\n",
    "        pts_xy = _safe_rand_points(H, W, need, rng)\n",
    "        for i in range(need):\n",
    "            z_idx = int(cz[i])\n",
    "            z0 = max(0, z_idx-8); z1 = min(cached_depth, z_idx+9)\n",
    "            slab = base[z0:z1]\n",
    "            mip = slab.max(axis=0) if slab.size else np.zeros((H,W), dtype=vol_u8.dtype)\n",
    "            cx, cy = pts_xy[i]\n",
    "            crop = _safe_crop_2d(mip, cx, cy, size=crop_size)\n",
    "            chan = cv2.resize(crop, (W, H), interpolation=cv2.INTER_LINEAR)\n",
    "            chans.append(chan[np.newaxis, ...])\n",
    "\n",
    "    chans = chans[:K]\n",
    "    return np.concatenate(chans, axis=0)\n",
    "\n",
    "def _build_model_input(series_path: str) -> Tuple[np.ndarray, str]:\n",
    "    sid = os.path.basename(series_path.rstrip(\"/\"))\n",
    "    vol_u8 = _load_cached_or_preprocess(series_path, sid)\n",
    "    K = getattr(CFG, \"max_localizer_crops\", 0) if getattr(CFG, \"use_localizers\", False) else 0\n",
    "    extra = _compose_localizer_channels(sid, vol_u8, K, crop_size=getattr(CFG, \"local_crop_size\", 128))\n",
    "    vol_u8 = np.concatenate([vol_u8, extra], axis=0)\n",
    "    # final check\n",
    "    C, H, W = vol_u8.shape\n",
    "    if C != ICFG.in_chans:\n",
    "        if C < ICFG.in_chans:\n",
    "            pad = np.zeros((ICFG.in_chans - C, H, W), dtype=vol_u8.dtype)\n",
    "            vol_u8 = np.concatenate([vol_u8, pad], axis=0)\n",
    "        else:\n",
    "            vol_u8 = vol_u8[:ICFG.in_chans]\n",
    "    return vol_u8, sid\n",
    "\n",
    "def _make_model_for_infer() -> nn.Module:\n",
    "    m = timm.create_model(\n",
    "        ICFG.model_name,\n",
    "        in_chans=ICFG.in_chans,\n",
    "        num_classes=ICFG.num_classes,\n",
    "        img_size=ICFG.img_size,\n",
    "        pretrained=False,\n",
    "    )\n",
    "    if ICFG.channels_last:\n",
    "        m = m.to(memory_format=torch.channels_last)\n",
    "    return m\n",
    "\n",
    "def _find_seed_dirs(base: Path, save_name: str, folds: List[int]) -> List[Path]:\n",
    "    \"\"\"Find seed directories like: base / f\"{save_name}_seedX_foldF\".\"\"\"\n",
    "    cand_dirs = []\n",
    "    if not base.exists():\n",
    "        return cand_dirs\n",
    "    for p in base.iterdir():\n",
    "        if not p.is_dir():\n",
    "            continue\n",
    "        name = p.name\n",
    "        if not name.startswith(f\"{save_name}_seed\"):\n",
    "            continue\n",
    "        if any(name.endswith(f\"_fold{f}\") for f in folds):\n",
    "            cand_dirs.append(p)\n",
    "    return sorted(cand_dirs)\n",
    "\n",
    "def _find_ckpt_in_dir(dirpath: Path) -> Optional[Path]:\n",
    "    # try preferred names anywhere under this dir\n",
    "    for fname in ICFG.ckpt_prefer:\n",
    "        hits = list(dirpath.rglob(fname))\n",
    "        if hits:\n",
    "            return hits[0]\n",
    "    # else: any *.pth (unique / or best guess)\n",
    "    all_pth = list(dirpath.rglob(\"*.pth\"))\n",
    "    if len(all_pth) == 1:\n",
    "        return all_pth[0]\n",
    "    ema_pth = [p for p in all_pth if \"ema\" in p.name.lower()]\n",
    "    if len(ema_pth) == 1:\n",
    "        return ema_pth[0]\n",
    "    return all_pth[0] if all_pth else None\n",
    "\n",
    "def _strip_prefix(state: dict, prefixes=(\"module.\", \"model.\", \"model_ema.\", \"ema.\", \"student.\")):\n",
    "    out = {}\n",
    "    for k, v in state.items():\n",
    "        kk = k\n",
    "        for p in prefixes:\n",
    "            if kk.startswith(p):\n",
    "                kk = kk[len(p):]\n",
    "        out[kk] = v\n",
    "    return out\n",
    "\n",
    "def _load_model_from_ckpt(ckpt_path: Path) -> nn.Module:\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    state = ckpt.get(\"state_dict\") or ckpt.get(\"model\") or ckpt\n",
    "    state = _strip_prefix(state)\n",
    "    m = _make_model_for_infer()\n",
    "    missing, unexpected = m.load_state_dict(state, strict=False)\n",
    "    if missing:\n",
    "        print(f\"[ckpt] missing {len(missing)} keys (ok if classifier head differs)\")\n",
    "    if unexpected:\n",
    "        print(f\"[ckpt] unexpected {len(unexpected)} keys (ignored)\")\n",
    "    m.to(ICFG.device).eval()\n",
    "    return m\n",
    "\n",
    "_MODELS: Dict[str, nn.Module] = {}\n",
    "\n",
    "def _ensure_models_loaded():\n",
    "    if _MODELS:\n",
    "        return\n",
    "    base = Path(ICFG.base_ckpt_dir)\n",
    "    seed_dirs = _find_seed_dirs(base, ICFG.save_name, ICFG.folds)\n",
    "    if not seed_dirs:\n",
    "        # fallback: treat base itself as a seed dir (single-seed uploads)\n",
    "        seed_dirs = [base]\n",
    "\n",
    "    loaded = 0\n",
    "    for sd in seed_dirs:\n",
    "        ckpt = _find_ckpt_in_dir(sd)\n",
    "        if ckpt is None:\n",
    "            continue\n",
    "        try:\n",
    "            model = _load_model_from_ckpt(ckpt)\n",
    "            _MODELS[sd.name] = model\n",
    "            loaded += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: failed to load {ckpt}: {e}\")\n",
    "\n",
    "    if loaded == 0:\n",
    "        raise FileNotFoundError(f\"No usable *.pth checkpoints under {base}.\")\n",
    "\n",
    "    # optional warmup\n",
    "    with torch.no_grad():\n",
    "        dummy = torch.randn(1, ICFG.in_chans, ICFG.img_size, ICFG.img_size, device=ICFG.device)\n",
    "        for m in _MODELS.values():\n",
    "            _ = m(dummy)\n",
    "\n",
    "# predict \n",
    "@torch.no_grad()\n",
    "def _predict_single(model: nn.Module, vol_u8: np.ndarray) -> np.ndarray:\n",
    "    x = torch.from_numpy(np.asarray(vol_u8)).to(torch.float32).div_(255.0).unsqueeze(0)\n",
    "    if ICFG.channels_last:\n",
    "        x = x.contiguous(memory_format=torch.channels_last)\n",
    "    x = x.to(ICFG.device, non_blocking=True)\n",
    "    with autocast(enabled=ICFG.use_amp):\n",
    "        logits = model(x)\n",
    "    prob = torch.sigmoid(logits.float()).cpu().numpy().squeeze(0)\n",
    "    return np.clip(prob, 1e-6, 1-1e-6)\n",
    "\n",
    "def _predict_ensemble(vol_u8: np.ndarray) -> np.ndarray:\n",
    "    _ensure_models_loaded()\n",
    "    preds = [_predict_single(m, vol_u8) for m in _MODELS.values()]\n",
    "    return np.mean(np.stack(preds, 0), 0)\n",
    "\n",
    "def _predict_inner(series_path: str) -> pl.DataFrame:\n",
    "    vol_u8, sid = _build_model_input(series_path)\n",
    "    pred = _predict_ensemble(vol_u8)\n",
    "    return pl.DataFrame([pred.tolist()], schema=TARGET_COLS)\n",
    "\n",
    "def predict(series_path: str) -> pl.DataFrame:\n",
    "    try:\n",
    "        return _predict_inner(series_path)\n",
    "    except Exception as e:\n",
    "        print(\"[infer] fallback due to:\", e)\n",
    "        return pl.DataFrame([[0.1]*NUM_CLASSES], schema=TARGET_COLS)\n",
    "    finally:\n",
    "        # required cleanup between served series\n",
    "        shared_dir = \"/kaggle/shared\"\n",
    "        shutil.rmtree(shared_dir, ignore_errors=True)\n",
    "        os.makedirs(shared_dir, exist_ok=True)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6eee3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T21:36:30.781072Z",
     "iopub.status.busy": "2025-09-25T21:36:30.780722Z",
     "iopub.status.idle": "2025-09-25T21:37:05.627077Z",
     "shell.execute_reply": "2025-09-25T21:37:05.626234Z"
    },
    "papermill": {
     "duration": 34.86022,
     "end_time": "2025-09-25T21:37:05.634447",
     "exception": false,
     "start_time": "2025-09-25T21:36:30.774227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kaggle_evaluation.rsna_inference_server as rsna_eval\n",
    "\n",
    "# Load once at startup (warm)\n",
    "_ensure_models_loaded()\n",
    "\n",
    "server = rsna_eval.RSNAInferenceServer(predict)\n",
    "\n",
    "if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "    server.serve()\n",
    "else:\n",
    "    server.run_local_gateway()\n",
    "    sub_df = pl.read_parquet(\"/kaggle/working/submission.parquet\")\n",
    "    display(sub_df)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13762876,
     "sourceId": 99552,
     "sourceType": "competition"
    },
    {
     "datasetId": 8285644,
     "sourceId": 13082129,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8317270,
     "sourceId": 13158243,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8347563,
     "sourceId": 13172964,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 65.625702,
   "end_time": "2025-09-25T21:37:08.758463",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-25T21:36:03.132761",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
